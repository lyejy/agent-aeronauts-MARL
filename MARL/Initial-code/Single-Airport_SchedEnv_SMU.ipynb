{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import random\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import stable_baselines3\n",
    "from stable_baselines3.sac.policies import MlpPolicy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for normal distribution truncation:\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def get_truncated_normal(mean, sd, low, upp):\n",
    "    return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get date sequence based on start_date and num_of_weeks:\n",
    "# Works for Single-Agent?\n",
    "\n",
    "def get_date_seq(start_date_arr, num_of_weeks_arr):\n",
    "    # Assert that both arguments are of type list or np.ndarray\n",
    "    assert isinstance(start_date_arr, (list, np.ndarray)), f\"Expected start_date_arr to be list or array, got {type(start_date_arr)}\"\n",
    "    assert isinstance(num_of_weeks_arr, (list, np.ndarray)), f\"Expected num_of_weeks_arr to be list or array, got {type(num_of_weeks_arr)}\"\n",
    "    \n",
    "    # Assert that both arrays/lists have the same length\n",
    "    assert len(start_date_arr) == len(num_of_weeks_arr), f\"start_date_arr and num_of_weeks_arr lengths mismatch: {len(start_date_arr)} vs {len(num_of_weeks_arr)}\"\n",
    "    \n",
    "    date_seq_arr = [None] * len(start_date_arr)  # Initialize as a list of None's.\n",
    "    for i in range(len(date_seq_arr)):\n",
    "        date_seq_arr[i] = list(range(int(start_date_arr[i]), int(start_date_arr[i]) + int(num_of_weeks_arr[i]) * 7, 7))\n",
    "    return date_seq_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get observation (still for single env, need to modify for multi-agent env):\n",
    "\n",
    "def full_obs(_cap_dem_chosen_req, number_of_actions):\n",
    "    _obs_min_arr = np.full((288+number_of_actions-1, ), 0)\n",
    "    for i in range(len(_cap_dem_chosen_req)):\n",
    "        _obs_min_arr[i+int((number_of_actions-1)/2)] = min(_cap_dem_chosen_req[i])\n",
    "    return _obs_min_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the one-hot-encoded vectors for departure and arrival airports:\n",
    "\n",
    "def one_hot_encode_airport(airport, num_airports):\n",
    "    encoding = np.zeros(num_airports)\n",
    "    encoding[airport] = 1\n",
    "    return encoding\n",
    "\n",
    "# Example usage\n",
    "num_airports = 3\n",
    "airport1 = 0\n",
    "airport2 = 1\n",
    "airport3 = 2\n",
    "\n",
    "encoded_airport1 = one_hot_encode_airport(airport1, num_airports)\n",
    "encoded_airport2 = one_hot_encode_airport(airport2, num_airports)\n",
    "encoded_airport3 = one_hot_encode_airport(airport3, num_airports)\n",
    "\n",
    "print(encoded_airport1)\n",
    "print(encoded_airport2)\n",
    "print(encoded_airport3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate full info for the arrival sides:\n",
    "\n",
    "def generate_info_arv(requests):\n",
    "    ts_arv = np.empty(shape=(len(requests),), dtype='object')\n",
    "    start_date_arv = np.empty(shape=(len(requests),), dtype='object')\n",
    "    #date_seq_arv = np.empty(shape=(len(requests),), dtype='object')\n",
    "    for i in range(len(requests)):\n",
    "        ts_arv[i] = requests[i][1] + requests[i][7]/5\n",
    "        if ts_arv[i] > 287:\n",
    "            ts_arv[i] = ts_arv[i] - 287\n",
    "            start_date_arv[i] = requests[i][2] + 1\n",
    "        else:\n",
    "            start_date_arv[i] = requests[i][2]\n",
    "    date_seq_arv = get_date_seq(start_date_arv, requests[:, 3])\n",
    "    return ts_arv, start_date_arv, date_seq_arv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_violate_id_set(airport_req_dict, num_airports):\n",
    "    violate_set = [] #(1: id, 2: airport, 3: dep, 4: arv)\n",
    "    for i in range(num_airports):\n",
    "        mask = ((airport_req_dict['req_{}'.format(i)][:, 8] + airport_req_dict['req_{}'.format(i)][:, 12]) >= 1)\n",
    "        _id_violate_per_airport = airport_req_dict['req_{}'.format(i)][mask, :][:,0]\n",
    "        violate_set.append(_id_violate_per_airport)\n",
    "    violate_set = np.concatenate(violate_set, axis=0)\n",
    "    violate_set = np.unique(violate_set)\n",
    "    return violate_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_violate_id_set_req_full(requests_full):\n",
    "    mask = ((requests_full[:, 8] + requests_full[:, 12]) >= 1)\n",
    "    violate_set_req_full = requests_full[mask, :][:,0]\n",
    "    return violate_set_req_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_req(violate_set, requests_full):\n",
    "    if not violate_set:\n",
    "        raise ValueError(\"The provided violate_set is empty!\")\n",
    "    _violate_index = random.choice(violate_set)\n",
    "    chosen_req = requests_full[requests_full[:,0] == _violate_index]\n",
    "    return chosen_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_cap_dem_dict(cap_dem_dict, num_airports):\n",
    "    cap_dem_dict_flat = {}\n",
    "    for i in range(num_airports):\n",
    "        cap_dem_dict_flat['req_{}'.format(i)] = cap_dem_dict['req_{}'.format(i)].flatten()\n",
    "    return cap_dem_dict_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get separated req per airport and store in a dict:\n",
    "\n",
    "def get_airport_req_dict(requests_full, num_airports):\n",
    "    airport_req_dict = {}\n",
    "    _belong_airport_dict = {}\n",
    "    for i in range(num_airports):\n",
    "        airport_req_dict['req_{}'.format(i)] = np.empty((0, 15)) #This one depends on the number of elements of a final request\n",
    "        _belong_airport_dict['req_{}'.format(i)] = np.full(num_airports, 0.0, dtype=float)\n",
    "        _belong_airport_dict['req_{}'.format(i)][i] = float(1.0)\n",
    "        _belong_airport_dict['req_{}'.format(i)] = _belong_airport_dict['req_{}'.format(i)].tolist()\n",
    "        \n",
    "    for i in range(len(requests_full)):\n",
    "        _found_dep = 0\n",
    "        _found_arv = 0\n",
    "        for k in range(num_airports):\n",
    "            #_found_dep = 0\n",
    "            #_found_arv = 0\n",
    "            if requests_full[i][5] == _belong_airport_dict['req_{}'.format(k)]:\n",
    "                _dep_req = np.append(requests_full[i], 1)\n",
    "                _dep_req = np.append(_dep_req, 0)\n",
    "                airport_req_dict['req_{}'.format(k)] = np.vstack((airport_req_dict['req_{}'.format(k)], _dep_req))\n",
    "                _found_dep = 1\n",
    "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 1)\n",
    "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 0)\n",
    "                #break\n",
    "            if requests_full[i][6] == _belong_airport_dict['req_{}'.format(k)]:\n",
    "                _arv_req = np.append(requests_full[i], 0)\n",
    "                _arv_req = np.append(_arv_req, 1)\n",
    "                airport_req_dict['req_{}'.format(k)] = np.vstack((airport_req_dict['req_{}'.format(k)], _arv_req))\n",
    "                _found_arv = 1\n",
    "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 0)\n",
    "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 1)\n",
    "                #break\n",
    "            if _found_dep + _found_arv == 2:\n",
    "                break\n",
    "        if _found_dep + _found_arv != 2:\n",
    "            print(\"Cannot found both dep and arv at req {}\".format(i))\n",
    "            \n",
    "    return airport_req_dict, _belong_airport_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_deterministic_capacity_dict(num_airports, cap_per_airport_arr): #This function is for a period of 182 days and 288 slots/ day\n",
    "    cap_dict = {}\n",
    "    for i in range(num_airports):\n",
    "        cap_dict['req_{}'.format(i)] = np.full((288, 182), cap_per_airport_arr[i])\n",
    "    return cap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_pot_dem_per_airport(airport_req_dict, num_airports): #Replace req_df to req_df_update to update pot_dem_df #To be replaced with final_sched\n",
    "    pot_dem_dict = {}\n",
    "    #TODO: increase speed\n",
    "    #13 dep 14 arv, 1 dep ts, 9 arv ts\n",
    "    for i in range(num_airports):\n",
    "        pot_dem_dict['req_{}'.format(i)] = np.full((288, 182), 0)\n",
    "        for k in range(len(airport_req_dict['req_{}'.format(i)])):\n",
    "            _time_slot = int(airport_req_dict['req_{}'.format(i)][k][1]) * int(airport_req_dict['req_{}'.format(i)][k][13]) + int(airport_req_dict['req_{}'.format(i)][k][9]) * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
    "            _date_seq = airport_req_dict['req_{}'.format(i)][k][4] * int(airport_req_dict['req_{}'.format(i)][k][13]) + airport_req_dict['req_{}'.format(i)][k][11] * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
    "            pot_dem_dict['req_{}'.format(i)][_time_slot, _date_seq] += 1\n",
    "    return pot_dem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cap_dem_dict(num_airports, cap_dict, pot_dem_dict):\n",
    "    cap_dem_dict = {}\n",
    "    for i in range(num_airports):\n",
    "        cap_dem_dict['req_{}'.format(i)] = cap_dict['req_{}'.format(i)] - pot_dem_dict['req_{}'.format(i)]\n",
    "    return cap_dem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_status_capacity(airport_req_dict, num_airports, cap_dem_dict, requests_full):\n",
    "    #Them cot cap_status o init:\n",
    "    for i in range(num_airports):\n",
    "        for k in range(len(airport_req_dict['req_{}'.format(i)])):\n",
    "            _time_slot = int(airport_req_dict['req_{}'.format(i)][k][1]) * int(airport_req_dict['req_{}'.format(i)][k][13]) + int(airport_req_dict['req_{}'.format(i)][k][9]) * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
    "            _date_seq = airport_req_dict['req_{}'.format(i)][k][4] * int(airport_req_dict['req_{}'.format(i)][k][13]) + airport_req_dict['req_{}'.format(i)][k][11] * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
    "            if all(x >= 0 for x in cap_dem_dict['req_{}'.format(i)][_time_slot, _date_seq]):\n",
    "                #print(self.cap_dem_arr[_time_slot, _date_seq])\n",
    "                airport_req_dict['req_{}'.format(i)][k][8] = 0\n",
    "                airport_req_dict['req_{}'.format(i)][k][12] = 0\n",
    "            else:\n",
    "                if airport_req_dict['req_{}'.format(i)][k][13] == 1:\n",
    "                    airport_req_dict['req_{}'.format(i)][k][8] = 1\n",
    "                    _indices = np.where(requests_full[:, 0] == airport_req_dict['req_{}'.format(i)][k][0])\n",
    "                    requests_full[_indices, 8] = 1\n",
    "                else:\n",
    "                    airport_req_dict['req_{}'.format(i)][k][12] = 1\n",
    "                    _indices = np.where(requests_full[:, 0] == airport_req_dict['req_{}'.format(i)][k][0])\n",
    "                    requests_full[_indices, 12] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previous single-agent simulator:\n",
    "\n",
    "class SchedEnv(gym.Env):\n",
    "    def __init__(self, number_of_actions, number_of_request, number_of_days):\n",
    "        \n",
    "        super(SchedEnv, self).__init__()\n",
    "        self.number_of_actions = int(number_of_actions) #Number of action should be an odd number\n",
    "        self.do_nothing_action = int((self.number_of_actions - 1)/2)\n",
    "        self.number_of_request = number_of_request\n",
    "        self.number_of_days = number_of_days\n",
    "        self.generate_scenario()\n",
    "        _cap_dem_flat = self.cap_dem_arr.flatten()\n",
    "        #Test lai so lan chay while o day, neu ko thi dung pattern (distribution) de chac chan over:\n",
    "        while min(_cap_dem_flat) >= 0:\n",
    "            self.generate_scenario()\n",
    "            _cap_dem_flat = self.cap_dem_arr.flatten()\n",
    "        self.update_status_capacity\n",
    "        #Check number of training step:\n",
    "        self.num_step = 0\n",
    "        \n",
    "        \n",
    "#         #Get remaining cap:\n",
    "#         self.cap_dem_df = self.cap_df - self.pot_dem_df\n",
    "        \n",
    "        #Define action and observation space:\n",
    "        self.action_space = spaces.Discrete(int(number_of_actions)) #TODO can change later if increase the number of shifting slot\n",
    "        #self.observation_space = spaces.Box(low= -np.inf, high= np.inf, shape=(5, 11), dtype=np.float)\n",
    "        self.observation_space = spaces.Box(low= -np.inf, high= np.inf, shape=(self.number_of_actions + 1,), dtype=float)\n",
    "        \n",
    "\n",
    "    def generate_scenario(self):\n",
    "        #Generate requests:\n",
    "#         number_of_request = 80\n",
    "#         number_of_days = 14\n",
    "\n",
    "#         time_slot = list(np.random.randint(low = 0, high=12, size=number_of_request))\n",
    "\n",
    "#         start_date = list(np.random.randint(low = 0, high=7, size=number_of_request))\n",
    "\n",
    "#         num_of_weeks = list(np.random.randint(low = 1, high=3, size=number_of_request))\n",
    "        \n",
    "    \n",
    "        #Change parameters here:\n",
    "#         self.number_of_request = number_of_request\n",
    "#         self.number_of_days = number_of_days\n",
    "\n",
    "        #Generate time slot, 2 peak time slots are 72 and 216 (TODO to be changed accordingly later):\n",
    "        ts_72 = get_truncated_normal(mean=72, sd=12, low=0, upp=287).rvs(int(round(self.number_of_request/2)))\n",
    "        ts_72 = np.round(ts_72)\n",
    "\n",
    "        ts_216 = get_truncated_normal(mean=216, sd=12, low=0, upp=287).rvs(int(round(self.number_of_request/2)))\n",
    "        ts_216 = np.round(ts_216)\n",
    "\n",
    "        ts_arr = np.concatenate((ts_72, ts_216))\n",
    "        ts_arr = ts_arr.astype(int)\n",
    "\n",
    "        #Generate start date:\n",
    "        start_date_arr = np.random.randint(low = 0, high=6, size=self.number_of_request) #This is only for more than 150 days only\n",
    "        start_date_arr = start_date_arr*30\n",
    "        #start_date_arr = np.random.randint(low = 0, high=self.number_of_days, size=self.number_of_request)\n",
    "\n",
    "        #Generate number of weeks:\n",
    "        _max_day = np.full(self.number_of_request, self.number_of_days - 1)\n",
    "\n",
    "        _remaining_days_arr = _max_day - start_date_arr\n",
    "\n",
    "        _max_num_of_weeks_arr = _remaining_days_arr // 7\n",
    "\n",
    "        # num_of_weeks_arr = np.random.randint(1, _max_num_of_weeks_arr + 2)\n",
    "\n",
    "        if (_max_num_of_weeks_arr + 2 > 1).all():\n",
    "            num_of_weeks_arr = np.random.randint(1, _max_num_of_weeks_arr + 2, size=_max_num_of_weeks_arr.shape)\n",
    "        else:\n",
    "            # Handle the condition where you cannot generate a random number in the given range.\n",
    "            # For instance, set a default value or adjust _max_num_of_weeks_arr appropriately.\n",
    "            num_of_weeks_arr = np.ones_like(_max_num_of_weeks_arr)\n",
    "\n",
    "\n",
    "        \n",
    "        #Generate index for requests:\n",
    "        \n",
    "        index_arr = np.array(list(range(self.number_of_request)))\n",
    "        \n",
    "        #Get date sequence:\n",
    "\n",
    "        date_seq_arr = get_date_seq(start_date_arr, num_of_weeks_arr)\n",
    "        \n",
    "        #Generate status cap:\n",
    "        \n",
    "        status_cap_arr = np.full((self.number_of_request,), 0)\n",
    "\n",
    "        # self.req_arr = np.stack((index_arr, ts_arr, start_date_arr, num_of_weeks_arr, date_seq_arr, status_cap_arr), axis=1)\n",
    "        # Step 1: Define dtypes\n",
    "        dtypes = [\n",
    "            ('index', int),\n",
    "            ('ts', float),\n",
    "            ('start_date', int),\n",
    "            ('num_of_weeks', int),\n",
    "            ('date_seq', 'O'),  # Object, can hold list or array\n",
    "            ('status_cap', int)\n",
    "        ]\n",
    "\n",
    "        # Step 2: Initialize structured array\n",
    "        combined_array = np.zeros(len(index_arr), dtype=dtypes)\n",
    "\n",
    "        # Step 3: Assign values\n",
    "        combined_array['index'] = index_arr\n",
    "        combined_array['ts'] = ts_arr\n",
    "        combined_array['start_date'] = start_date_arr\n",
    "        combined_array['num_of_weeks'] = num_of_weeks_arr\n",
    "        combined_array['date_seq'] = date_seq_arr\n",
    "        combined_array['status_cap'] = status_cap_arr\n",
    "\n",
    "        self.req_arr = combined_array\n",
    "        \n",
    "        #Generate capacity:\n",
    "        self.cap_arr = np.full((288, self.number_of_days), 20)\n",
    "        \n",
    "        \n",
    "        #Create final_sched:\n",
    "        self.final_sched_arr = self.req_arr.copy()\n",
    "        \n",
    "        #Get potential demand: #Check again the function here (turn to array)\n",
    "        self.pot_dem_arr = self.get_initial_pot_dem()\n",
    "        \n",
    "        #Get remaining cap:\n",
    "        self.cap_dem_arr = self.cap_arr - self.pot_dem_arr\n",
    "        \n",
    "    def get_date_seq(row):\n",
    "        return(list(range(row['start_date'], row['start_date'] + row['num_of_weeks']*7, 7)))\n",
    "    \n",
    "    def check_in_date_seq(row, value):\n",
    "        if value in row['date_seq']:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def get_initial_pot_dem(self): #Replace req_df to req_df_update to update pot_dem_df #To be replaced with final_sched\n",
    "        pot_dem_arr = np.full((288, self.number_of_days), 0)\n",
    "        #TODO: increase speed\n",
    "        for i in range(len(self.final_sched_arr)):\n",
    "            _time_slot = int(self.final_sched_arr['ts'][i])\n",
    "            _date_seq = self.final_sched_arr['date_seq'][i]\n",
    "            pot_dem_arr[_time_slot, _date_seq] += 1\n",
    "        return pot_dem_arr    \n",
    "\n",
    "\n",
    "    #To be updated:            \n",
    "    def update_pot_dem(self, action):\n",
    "        if not self.check_outbound(action):\n",
    "            if action != self.do_nothing_action:\n",
    "                _time_slot = int(self.final_sched_arr['ts'][i])\n",
    "                _date_seq = self.final_sched_arr['date_seq'][i]\n",
    "                self.pot_dem_arr[_time_slot, _date_seq] -= 1\n",
    "                self.pot_dem_arr[_time_slot + action - self.do_nothing_action, _date_seq] += 1       \n",
    "            \n",
    "    def update_status_capacity(self):\n",
    "        #Them cot cap_status o init:\n",
    "        for i in range(len(self.final_sched_arr)):\n",
    "            _time_slot = int(self.final_sched_arr[i,1])\n",
    "            _date_seq = self.final_sched_arr[i,4]\n",
    "            if all(x >= 0 for x in self.cap_dem_arr[_time_slot, _date_seq]):\n",
    "                #print(self.cap_dem_arr[_time_slot, _date_seq])\n",
    "                self.final_sched_arr[i,5] = 0\n",
    "            else:\n",
    "                self.final_sched_arr[i,5] = 1\n",
    "        \n",
    "    def get_req(self):\n",
    "            \n",
    "        #Them cot status capacity of req trong req_df and update moi khi take action, chu y la con lien quan toi req khac\n",
    "        _chosen_req = self.final_sched_arr[self.final_sched_arr[:,5] == 1]\n",
    "        #print(_chosen_req)\n",
    "        #print(self.final_sched_arr)\n",
    "        #print(np.unique(env.cap_dem_arr))\n",
    "        self.chosen_req_arr = random.choice(_chosen_req)\n",
    "        #return self.chosen_req_arr\n",
    "           \n",
    "    def check_outbound(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    #TODO: change to 288 when changing time slot\n",
    "    def _take_action(self, action):\n",
    "        if not self.check_outbound(action):\n",
    "            self.final_sched_arr[self.chosen_req_arr[0],1] += action - self.do_nothing_action\n",
    "            \n",
    "    #Additional func:\n",
    "    \n",
    "#     def full_obs(_cap_dem_chosen_req):\n",
    "#         _obs_min_arr = np.full((288+5*2, ), 0)\n",
    "#         for i in range(len(_cap_dem_chosen_req)):\n",
    "#             _obs_min_arr[i+5] = min(_cap_dem_chosen_req[i])\n",
    "#         return _obs_min_arr\n",
    "            \n",
    "    \n",
    "    def _next_observation(self):\n",
    "        self.get_req()\n",
    "        _time_slot = self.chosen_req_arr[1]\n",
    "        _num_of_weeks = self.chosen_req_arr[3]\n",
    "        _date_seq = self.chosen_req_arr[4]\n",
    "        _cap_dem_chosen_req = self.cap_dem_arr[:, _date_seq].copy()\n",
    "        #print(self.number_of_actions, type(self.number_of_actions))\n",
    "        _obs_min_arr = full_obs(_cap_dem_chosen_req, self.number_of_actions)\n",
    "        _obs_time_slot_related = list(range(_time_slot, _time_slot + self.number_of_actions, 1))\n",
    "        _cap_dem_obs = _obs_min_arr[_obs_time_slot_related]\n",
    "\n",
    "        self.obs = np.append(_cap_dem_obs, _num_of_weeks)\n",
    "        \n",
    "        return self.obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        self._take_action(action)\n",
    "        self.update_pot_dem(action)\n",
    "        #Update cap_dem_df:\n",
    "        self.cap_dem_arr = self.cap_arr - self.pot_dem_arr\n",
    "        self.update_status_capacity()\n",
    "        \n",
    "        \n",
    "        #Reward part: (TODO change to 288), must add reward for violating capacity\n",
    "        local_reward = 0\n",
    "        if self.check_outbound(action):\n",
    "            local_reward = -1\n",
    "        else:\n",
    "            local_reward = 0.1*(-abs(action-self.do_nothing_action)*0.5*self.chosen_req_arr[3]) #TODO change if increase number of actions\n",
    "#         print('Local reward is: \\n')\n",
    "#         print(local_reward)\n",
    "        \n",
    "        reward_action = self.reward_action(action) #Must put before next obs\n",
    "        \n",
    "        self.num_step += 1\n",
    "        done = False\n",
    "        \n",
    "        _cap_dem_violate = self.cap_dem_arr[self.cap_dem_arr < 0]\n",
    "        if _cap_dem_violate.size == 0:\n",
    "            done = True\n",
    "            obs = np.zeros((self.number_of_actions + 1,)) #Change to a positive number\n",
    "            global_reward = 100 #TODO change according to the number of req\n",
    "            \n",
    "        elif self.num_step == len(self.req_arr)*5: #TODO parameter\n",
    "            done = True\n",
    "            obs = np.zeros((self.number_of_actions + 1,))\n",
    "            #_cap_dem_check = _cap_dem_check.values.flatten()\n",
    "            _violate_num = self.cap_dem_arr[self.cap_dem_arr < 0]\n",
    "            global_reward = -sum(abs(_violate_num))*10\n",
    "            \n",
    "        else:\n",
    "            global_reward = 0\n",
    "            obs = self._next_observation()\n",
    "        \n",
    "        reward_time_step = -0.5\n",
    "            \n",
    "        reward = local_reward + global_reward + reward_action + reward_time_step\n",
    "        reward = float(reward)\n",
    "    \n",
    "        return obs, reward, done, {}\n",
    "        \n",
    "    def reward_action(self, action):\n",
    "        _time_slot = self.chosen_req_arr[1]\n",
    "        \n",
    "        _num_of_weeks = self.chosen_req_arr[3]\n",
    "\n",
    "        _date_seq = self.chosen_req_arr[4]\n",
    "        \n",
    "        _cap_dem_chosen_req = self.cap_dem_arr[:,_date_seq].copy()\n",
    "        \n",
    "        \n",
    "        if self.check_outbound(action):\n",
    "            reward_action = 0\n",
    "        else:\n",
    "            if action == self.do_nothing_action:\n",
    "                _cap_dem_inital = _cap_dem_chosen_req[_time_slot]\n",
    "            else:\n",
    "                _cap_dem_inital = _cap_dem_chosen_req[_time_slot] - 1 #Since we have update demand\n",
    "            #print(\"Cap dem initial:\", _cap_dem_inital)\n",
    "            _cap_dem_new_slot = _cap_dem_chosen_req[_time_slot + action - self.do_nothing_action]\n",
    "            #print(\"Cap dem new:\", _cap_dem_new_slot)\n",
    "            if len(_cap_dem_inital[_cap_dem_inital < 0]) == 0:\n",
    "                initial_under = True\n",
    "            else:\n",
    "                initial_under = False\n",
    "\n",
    "            if len(_cap_dem_new_slot[_cap_dem_new_slot < 0]) == 0:\n",
    "                new_slot_under = True\n",
    "            else:\n",
    "                new_slot_under = False\n",
    "\n",
    "            if initial_under and new_slot_under:\n",
    "                reward_action = 0\n",
    "\n",
    "            elif initial_under and not new_slot_under:  #TODO update to -5*num_of_weeks\n",
    "                #reward_action = -5\n",
    "                reward_action = -(self.number_of_actions*_num_of_weeks*0.1)/4\n",
    "\n",
    "            elif not initial_under and new_slot_under:\n",
    "                #reward_action = 5\n",
    "                reward_action = (self.number_of_actions*_num_of_weeks*0.1)/4\n",
    "\n",
    "            else:\n",
    "                reward_action = 0\n",
    "        \n",
    "        #print('Reward action:\\n', reward_action)\n",
    "        return reward_action\n",
    "    \n",
    "    def check_outbound(self, action):\n",
    "        _time_slot = self.chosen_req_arr[1]\n",
    "        if ((_time_slot + (action - self.do_nothing_action)) < 0) or ((_time_slot + (action - self.do_nothing_action)) > 287):\n",
    "            outbound = True\n",
    "        else:\n",
    "            outbound = False\n",
    "        #print('Time slot:\\n', _id)\n",
    "        #print('Action:\\n', action)\n",
    "        #print('Outbound:\\n', outbound)\n",
    "        return outbound\n",
    "        \n",
    "    \n",
    "    #TODO change to 288\n",
    "    def check(self):\n",
    "        #TODO change according to capacity\n",
    "        if sum(sum(self.pot_dem_arr)) == sum(self.req_arr[:,3]):\n",
    "            print('Pot_dem_arr passed!')\n",
    "        else:\n",
    "            print('+++++++++++++++++++++++++')\n",
    "            raise ValueError('Check Pot_dem_arr!')\n",
    "\n",
    "        if sum(sum(self.cap_dem_arr)) == 14*288*2 - sum(self.req_arr[:,3]):\n",
    "            print('Pot_dem_df passed!')\n",
    "        else:\n",
    "            print('+++++++++++++++++++++++++')\n",
    "            raise ValueError('Check pot_dem_df!')\n",
    "            \n",
    "    #TODO: Implement for valuation:\n",
    "    def check_num_violate(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        #done = False\n",
    "        \n",
    "        self.generate_scenario()\n",
    "        _cap_dem_flat = self.cap_dem_arr.flatten()\n",
    "        #Test lai so lan chay while o day, neu ko thi dung pattern (distribution) de chac chan over:\n",
    "        while min(_cap_dem_flat) >= 0:\n",
    "            self.generate_scenario()\n",
    "            _cap_dem_flat = self.cap_dem_arr.flatten()\n",
    "        self.update_status_capacity()\n",
    "        print('Number of violation: ', len(_cap_dem_flat[_cap_dem_flat < 0]))\n",
    "        \n",
    "        #print('Min cap dem flat:\\n', min(_cap_dem_flat))\n",
    "\n",
    "        #Check number of training step:\n",
    "        self.num_step = 0\n",
    "        #print('Initial sched:\\n', env.req_df)\n",
    "        #print('Initial cap dem:\\n', env.cap_dem_df)\n",
    "        \n",
    "        \n",
    "        return self._next_observation()\n",
    "\n",
    "    #Add them eval schedule delay among requests (min, max, mean schedule delay)\n",
    "    def eval(self):\n",
    "        _initial_pot_dem_arr = np.full((288, self.number_of_days), 0)\n",
    "        for i in range(len(self.req_arr)):\n",
    "            _time_slot = int(self.req_arr[i,1])\n",
    "            _date_seq = self.req_arr[i,4]\n",
    "            _initial_pot_dem_arr[_time_slot, _date_seq] += 1\n",
    "        _initial_cap_dem = self.cap_arr - _initial_pot_dem_arr\n",
    "        \n",
    "        _initial_cap_dem_flat = _initial_cap_dem.flatten()\n",
    "        _initial_violate = len(_initial_cap_dem_flat[_initial_cap_dem_flat < 0])\n",
    "        print('Initial violation is: ', _initial_violate)\n",
    "        _final_cap_dem_flat = self.cap_dem_arr.flatten()\n",
    "        _final_violate = len(_final_cap_dem_flat[_final_cap_dem_flat < 0])\n",
    "        print('Final violation is: ', _final_violate)\n",
    "        _total_sched_delay = sum(abs(self.req_arr[:,1] - self.final_sched_arr[:,1])* self.req_arr[:,3])\n",
    "        print('Total schedule delay is: ', _total_sched_delay)\n",
    "        _max_shift = max(abs(self.req_arr[:,1] - self.final_sched_arr[:,1]))\n",
    "        print('Max shift: ', _max_shift)\n",
    "        return _initial_violate, _final_violate, _total_sched_delay, _max_shift\n",
    "        \n",
    "        \n",
    "    def get_scenario(self):\n",
    "        return self.req_arr, self.cap_arr\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JY's code to test and visualize SARL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the agent: Q-learning algorithm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha, gamma, n_actions):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.n_actions = n_actions\n",
    "        self.q_table = np.zeros(n_actions)\n",
    "\n",
    "    def choose_action(self, observation, epsilon):\n",
    "        if np.random.random() < epsilon:\n",
    "            return np.random.choice(self.n_actions)\n",
    "        return np.argmax(self.q_table)\n",
    "\n",
    "    def learn(self, old_observation, reward, new_observation, action):\n",
    "        predict = self.q_table[action]\n",
    "        target = reward + self.gamma * np.max(self.q_table)\n",
    "        self.q_table[action] += self.alpha * (target - predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_agent(env, agent, n_epochs, epsilon=1.0, epsilon_decay=0.995, min_epsilon=0.01):\n",
    "    rewards = []\n",
    "    for i in range(n_epochs):\n",
    "        total_reward = 0\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.choose_action(obs, epsilon)\n",
    "            new_obs, reward, done, info = env.step(action)\n",
    "            agent.learn(obs, reward, new_obs, action)\n",
    "            total_reward += reward\n",
    "            obs = new_obs\n",
    "        rewards.append(total_reward)\n",
    "        epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "        print(f\"Epoch {i + 1}/{n_epochs} completed. Accumulated reward: {total_reward:.2f}\")\n",
    "    return rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_rewards(rewards):\n",
    "    plt.plot(rewards, label='Reward per epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.title('Training Convergence')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize environment and agent\n",
    "    env = SchedEnv(number_of_actions=5, number_of_request=10, number_of_days=200)\n",
    "    agent = QLearningAgent(alpha=0.1, gamma=0.95, n_actions=5)\n",
    "    \n",
    "    # Train the agent\n",
    "    rewards = train_agent(env, agent, n_epochs=1000)\n",
    "    \n",
    "    # Visualize the results\n",
    "    plot_rewards(rewards)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
