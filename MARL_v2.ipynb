{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT9Xf2Mx2nFu",
        "outputId": "e781c227-ffcf-4c66-fec6-1a1b5b5cf4d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gym\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /Users/reginachua/anaconda3/lib/python3.11/site-packages (from gym) (1.24.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/reginachua/anaconda3/lib/python3.11/site-packages (from gym) (2.2.1)\n",
            "Collecting gym-notices>=0.0.4 (from gym)\n",
            "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827620 sha256=00f778a156162a9c4568dadb398771cd83f4f47fc489ab1e4f8b921ec6d2b6fb\n",
            "  Stored in directory: /Users/reginachua/Library/Caches/pip/wheels/1c/77/9e/9af5470201a0b0543937933ee99ba884cd237d2faefe8f4d37\n",
            "Successfully built gym\n",
            "Installing collected packages: gym-notices, gym\n",
            "Successfully installed gym-0.26.2 gym-notices-0.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qBGg4yjk1s6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Necessary imports\n",
        "import gym\n",
        "from gym import spaces\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import base64, io\n",
        "import numpy as np\n",
        "from collections import deque, namedtuple\n",
        "\n",
        "# For visualization\n",
        "from IPython.display import HTML\n",
        "from IPython import display \n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Function for normal distribution truncation:\n",
        "\n",
        "from scipy.stats import truncnorm\n",
        "\n",
        "def get_truncated_normal(mean, sd, low, upp):\n",
        "    return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
        "\n",
        "#Function to get date sequence based on start_date and num_of_weeks:\n",
        "# Works for Multi-Agent?\n",
        "\n",
        "def get_date_seq(start_date_arr, num_of_weeks_arr): #start_date index 2, num_of_weeks index 3\n",
        "    date_seq_arr = np.empty(shape=(len(start_date_arr),), dtype='object')\n",
        "    for i in range(len(date_seq_arr)):\n",
        "        date_seq_arr[i] = list(range(int(start_date_arr[i]), int(start_date_arr[i]) + int(num_of_weeks_arr[i])*7, 7))\n",
        "    return date_seq_arr\n",
        "\n",
        "#Function to get observation (still for single env, need to modify for multi-agent env):\n",
        "\n",
        "def full_obs(_cap_dem_chosen_req, number_of_actions):\n",
        "    _obs_min_arr = np.full((288+number_of_actions-1, ), 0)\n",
        "    for i in range(len(_cap_dem_chosen_req)):\n",
        "        _obs_min_arr[i+int((number_of_actions-1)/2)] = min(_cap_dem_chosen_req[i])\n",
        "    return _obs_min_arr\n",
        "\n",
        "#Function to get the one-hot-encoded vectors for departure and arrival airports:\n",
        "\n",
        "def one_hot_encode_airport(airport, num_airports):\n",
        "    encoding = np.zeros(num_airports)\n",
        "    encoding[airport] = 1\n",
        "    return encoding\n",
        "\n",
        "# Example usage\n",
        "num_airports = 3\n",
        "airport1 = 0\n",
        "airport2 = 1\n",
        "airport3 = 2\n",
        "\n",
        "encoded_airport1 = one_hot_encode_airport(airport1, num_airports)\n",
        "encoded_airport2 = one_hot_encode_airport(airport2, num_airports)\n",
        "encoded_airport3 = one_hot_encode_airport(airport3, num_airports)\n",
        "\n",
        "print(encoded_airport1)\n",
        "print(encoded_airport2)\n",
        "print(encoded_airport3)\n",
        "\n",
        "#Generate full info for the arrival sides:\n",
        "\n",
        "def generate_info_arv(requests):\n",
        "    ts_arv = np.empty(shape=(len(requests),), dtype='object')\n",
        "    start_date_arv = np.empty(shape=(len(requests),), dtype='object')\n",
        "    #date_seq_arv = np.empty(shape=(len(requests),), dtype='object')\n",
        "    for i in range(len(requests)):\n",
        "        ts_arv[i] = requests[i][1] + requests[i][7]/5\n",
        "        if ts_arv[i] > 287:\n",
        "            ts_arv[i] = ts_arv[i] - 287\n",
        "            start_date_arv[i] = requests[i][2] + 1\n",
        "        else:\n",
        "            start_date_arv[i] = requests[i][2]\n",
        "    date_seq_arv = get_date_seq(start_date_arv, requests[:, 3])\n",
        "    return ts_arv, start_date_arv, date_seq_arv\n",
        "\n",
        "#Generate the multi-agent scenario:\n",
        "\n",
        "#=======================================================\n",
        "\n",
        "#Modify the distribution based on historical data later:\n",
        "def generate_scenario(number_of_requests, num_airports, cap_dict):\n",
        "    \n",
        "    #number_of_requests = 15000\n",
        "    ts_72 = get_truncated_normal(mean=72, sd=12, low=0, upp=287).rvs(int(round(number_of_requests/2)))\n",
        "    ts_72 = np.round(ts_72)\n",
        "\n",
        "    ts_216 = get_truncated_normal(mean=216, sd=12, low=0, upp=287).rvs(int(round(number_of_requests/2)))\n",
        "    ts_216 = np.round(ts_216)\n",
        "\n",
        "    ts_dep = np.concatenate((ts_72, ts_216))\n",
        "    ts_dep = ts_dep.astype(int)\n",
        "\n",
        "    #Generate start date:\n",
        "\n",
        "    start_date_dep = np.random.randint(low = 0, high=146, size=number_of_requests) #146 because period is 182 days and we consider series which span at least 5 weeks (+35 days)\n",
        "\n",
        "    #Generate number of weeks:\n",
        "\n",
        "    _max_day = np.full(number_of_requests, 182 - 1)\n",
        "\n",
        "    _remaining_days = _max_day - start_date_dep\n",
        "\n",
        "    _max_num_of_weeks = _remaining_days // 7\n",
        "\n",
        "    num_of_weeks = np.random.randint(5, _max_num_of_weeks + 1)\n",
        "\n",
        "    #Generate index for requests:\n",
        "\n",
        "    index = np.array(list(range(number_of_requests)))\n",
        "\n",
        "    #Generate origin (0 and 1 are two considered origin airports, 2 represent other airports, encoded in one-hot vector):\n",
        "\n",
        "    #num_airports = 3\n",
        "    origin_airport = np.empty(shape=(number_of_requests,), dtype='object')\n",
        "    destination_airport = np.empty(shape=(number_of_requests,), dtype='object')\n",
        "    for i in range(number_of_requests):\n",
        "        _org_airport = one_hot_encode_airport(random.randint(0,2), num_airports)\n",
        "        _org_airport_list = _org_airport.tolist()\n",
        "        origin_airport[i] = _org_airport_list\n",
        "        #Generate destination (the destination will be different with the origin):\n",
        "        _dest_airport = _org_airport.copy()\n",
        "        while np.array_equal(_dest_airport, _org_airport):\n",
        "            np.random.shuffle(_dest_airport)\n",
        "        _dest_airport_list = _dest_airport.tolist()\n",
        "        destination_airport[i] = _dest_airport_list\n",
        "\n",
        "    #Generate flying time (assume between airport 0 and 1 is 2 hour, 0 to 2 and 1 to 2 is arbitrary):\n",
        "\n",
        "    fly_time = np.empty(shape=(number_of_requests,), dtype='object')\n",
        "    for i in range (number_of_requests):\n",
        "        if origin_airport[i] == list([1.0, 0.0, 0.0]) and destination_airport[i] == list([0.0, 1.0, 0.0]):\n",
        "            fly_time[i] = 120\n",
        "        elif origin_airport[i] == list([1.0, 0.0, 0.0]) and destination_airport[i] == list([0.0, 0.0, 1.0]):\n",
        "            fly_time[i] = random.choice([60, 120, 180])\n",
        "        elif origin_airport[i] == list([0.0, 1.0, 0.0]) and destination_airport[i] == list([1.0, 0.0, 0.0]):\n",
        "            fly_time[i] = 120\n",
        "        elif origin_airport[i] == list([0.0, 1.0, 0.0]) and destination_airport[i] == list([0.0, 0.0, 1.0]):\n",
        "            fly_time[i] = random.choice([60, 120, 180])\n",
        "        elif origin_airport[i] == list([0.0, 0.0, 1.0]) and destination_airport[i] == list([1.0, 0.0, 0.0]):\n",
        "            fly_time[i] = random.choice([60, 120, 180])\n",
        "        elif origin_airport[i] == list([0.0, 0.0, 1.0]) and destination_airport[i] == list([0.0, 1.0, 0.0]):\n",
        "            fly_time[i] = random.choice([60, 120, 180])\n",
        "\n",
        "    #Get date sequence (date seq is actually a list):\n",
        "\n",
        "    date_seq_dep = get_date_seq(start_date_dep, num_of_weeks)\n",
        "\n",
        "    #Generate status cap:\n",
        "\n",
        "    status_cap_dep = np.full((number_of_requests,), 0)\n",
        "    status_cap_arv = np.full((number_of_requests,), 0)\n",
        "    \n",
        "\n",
        "    requests = np.stack((index, ts_dep, start_date_dep, num_of_weeks, date_seq_dep, origin_airport, destination_airport, fly_time, status_cap_dep), axis=1)\n",
        "\n",
        "    #Generate full info for the arv side:\n",
        "\n",
        "    ts_arv, start_date_arv, date_seq_arv = generate_info_arv(requests)\n",
        "\n",
        "    #pseudo_belong_dep = np.full((number_of_requests,), 0)\n",
        "    #pseudo_belong_arv = np.full((number_of_requests,), 0)\n",
        "    \n",
        "    # Define requests_full as dtype object\n",
        "    # requests_full = np.stack((index, ts_dep, start_date_dep, num_of_weeks, date_seq_dep, origin_airport, destination_airport, fly_time, status_cap_dep, ts_arv, start_date_arv, date_seq_arv, status_cap_arv), axis=1)\n",
        "    num_entries = len(index)  # Given that 'index' is defined using np.array(list(range(number_of_requests)))\n",
        "    # Create an empty array of the desired shape with dtype=object\n",
        "    requests_full = np.empty((num_entries, 13), dtype=object)\n",
        "    # Fill the array\n",
        "    data = [index, ts_dep, start_date_dep, num_of_weeks, date_seq_dep, origin_airport, destination_airport, fly_time, status_cap_dep, ts_arv, start_date_arv, date_seq_arv, status_cap_arv]\n",
        "    for i, column_data in enumerate(data):\n",
        "        requests_full[:, i] = column_data\n",
        "\n",
        "    # airport_req_dict: A dictionary where each key corresponds to a specific airport's requirements. \n",
        "    # The key format is 'req_i', where i is the index of the airport. \n",
        "    # The value for each key is a numpy array, with each row representing a request and the columns containing different attributes of that request.\n",
        "    airport_req_dict, _belong_airport_dict = get_airport_req_dict(requests_full, num_airports)\n",
        "\n",
        "    pot_dem_dict = get_initial_pot_dem_per_airport(airport_req_dict, num_airports)\n",
        "\n",
        "    cap_dem_dict = get_cap_dem_dict(num_airports, cap_dict, pot_dem_dict)\n",
        "\n",
        "    return requests_full, airport_req_dict, _belong_airport_dict, pot_dem_dict, cap_dem_dict\n",
        "\n",
        "    #Generate capacity:\n",
        "\n",
        "    #cap_arr = np.full((288, 182), 20)\n",
        "\n",
        "    #Create final_sched:\n",
        "\n",
        "    #final_sched_arr = req_arr.copy()\n",
        "\n",
        "    #Get potential demand: #Check again the function here (turn to array)\n",
        "    #pot_dem_arr = get_initial_pot_dem()\n",
        "\n",
        "    #Get remaining cap:\n",
        "    #cap_dem_arr = cap_arr - pot_dem_arr\n",
        "\n",
        "    #  identify which requests from a set of airports violate a specific condition\n",
        "# For each airport (from 0 to num_airports - 1), the function checks a condition based on the status_cap_dep and status_cap_arv \n",
        "# of the associated numpy array. If the sum of these two columns is greater than or equal to 1 (mask), it means that capacity is exceeded.\n",
        "# For every airport that has violations, the function extracts the IDs of these violating requests.\n",
        "# The function accumulates these IDs in the violate_set list.\n",
        "\n",
        "def get_violate_id_set(airport_req_dict, num_airports):\n",
        "    violate_set = [] #(1: id, 2: airport, 3: dep, 4: arv)\n",
        "    for i in range(num_airports):\n",
        "        mask = ((airport_req_dict['req_{}'.format(i)][:, 8] + airport_req_dict['req_{}'.format(i)][:, 12]) >= 1)\n",
        "        _id_violate_per_airport = airport_req_dict['req_{}'.format(i)][mask, :][:,0]\n",
        "        violate_set.append(_id_violate_per_airport)\n",
        "    violate_set = np.concatenate(violate_set, axis=0)\n",
        "    violate_set = np.unique(violate_set)\n",
        "    return violate_set\n",
        "\n",
        "def get_violate_id_set_req_full(requests_full):\n",
        "    mask = ((requests_full[:, 8] + requests_full[:, 12]) >= 1)\n",
        "    violate_set_req_full = requests_full[mask, :][:,0]\n",
        "    return violate_set_req_full\n",
        "\n",
        "def get_req(violate_set, requests_full):\n",
        "    # if not violate_set:\n",
        "    #     raise ValueError(\"The provided violate_set is empty!\")\n",
        "    _violate_index = random.choice(violate_set)\n",
        "    chosen_req = requests_full[requests_full[:,0] == _violate_index]\n",
        "    return chosen_req\n",
        "\n",
        "def flatten_cap_dem_dict(cap_dem_dict, num_airports):\n",
        "    cap_dem_dict_flat = {}\n",
        "    for i in range(num_airports):\n",
        "        cap_dem_dict_flat['req_{}'.format(i)] = cap_dem_dict['req_{}'.format(i)].flatten()\n",
        "    return cap_dem_dict_flat\n",
        "\n",
        "#Get separated req per airport and store in a dict:\n",
        "\n",
        "def get_airport_req_dict(requests_full, num_airports):\n",
        "    airport_req_dict = {}\n",
        "    _belong_airport_dict = {}\n",
        "    for i in range(num_airports):\n",
        "        airport_req_dict['req_{}'.format(i)] = np.empty((0, 15)) #This one depends on the number of elements of a final request\n",
        "        _belong_airport_dict['req_{}'.format(i)] = np.full(num_airports, 0.0, dtype=float)\n",
        "        _belong_airport_dict['req_{}'.format(i)][i] = float(1.0)\n",
        "        _belong_airport_dict['req_{}'.format(i)] = _belong_airport_dict['req_{}'.format(i)].tolist()\n",
        "        \n",
        "    for i in range(len(requests_full)):\n",
        "        _found_dep = 0\n",
        "        _found_arv = 0\n",
        "        for k in range(num_airports):\n",
        "            #_found_dep = 0\n",
        "            #_found_arv = 0\n",
        "            if requests_full[i][5] == _belong_airport_dict['req_{}'.format(k)]:\n",
        "                _dep_req = np.append(requests_full[i], 1)\n",
        "                _dep_req = np.append(_dep_req, 0)\n",
        "                airport_req_dict['req_{}'.format(k)] = np.vstack((airport_req_dict['req_{}'.format(k)], _dep_req))\n",
        "                _found_dep = 1\n",
        "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 1)\n",
        "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 0)\n",
        "                #break\n",
        "            if requests_full[i][6] == _belong_airport_dict['req_{}'.format(k)]:\n",
        "                _arv_req = np.append(requests_full[i], 0)\n",
        "                _arv_req = np.append(_arv_req, 1)\n",
        "                airport_req_dict['req_{}'.format(k)] = np.vstack((airport_req_dict['req_{}'.format(k)], _arv_req))\n",
        "                _found_arv = 1\n",
        "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 0)\n",
        "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 1)\n",
        "                #break\n",
        "            if _found_dep + _found_arv == 2:\n",
        "                break\n",
        "        if _found_dep + _found_arv != 2:\n",
        "            print(\"Cannot found both dep and arv at req {}\".format(i))\n",
        "            \n",
        "    return airport_req_dict, _belong_airport_dict\n",
        "\n",
        "def generate_deterministic_capacity_dict(num_airports, cap_per_airport_arr): #This function is for a period of 182 days and 288 slots/ day\n",
        "    cap_dict = {}\n",
        "    for i in range(num_airports):\n",
        "        cap_dict['req_{}'.format(i)] = np.full((288, 182), cap_per_airport_arr[i])\n",
        "    return cap_dict\n",
        "\n",
        "def get_initial_pot_dem_per_airport(airport_req_dict, num_airports): #Replace req_df to req_df_update to update pot_dem_df #To be replaced with final_sched\n",
        "    pot_dem_dict = {}\n",
        "    #TODO: increase speed\n",
        "    #13 dep 14 arv, 1 dep ts, 9 arv ts\n",
        "    for i in range(num_airports):\n",
        "        pot_dem_dict['req_{}'.format(i)] = np.full((288, 182), 0)\n",
        "        for k in range(len(airport_req_dict['req_{}'.format(i)])):\n",
        "            _time_slot = int(airport_req_dict['req_{}'.format(i)][k][1]) * int(airport_req_dict['req_{}'.format(i)][k][13]) + int(airport_req_dict['req_{}'.format(i)][k][9]) * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
        "            _date_seq = airport_req_dict['req_{}'.format(i)][k][4] * int(airport_req_dict['req_{}'.format(i)][k][13]) + airport_req_dict['req_{}'.format(i)][k][11] * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
        "            pot_dem_dict['req_{}'.format(i)][_time_slot, _date_seq] += 1\n",
        "    return pot_dem_dict\n",
        "\n",
        "def get_cap_dem_dict(num_airports, cap_dict, pot_dem_dict):\n",
        "    cap_dem_dict = {}\n",
        "    for i in range(num_airports):\n",
        "        cap_dem_dict['req_{}'.format(i)] = cap_dict['req_{}'.format(i)] - pot_dem_dict['req_{}'.format(i)]\n",
        "    return cap_dem_dict\n",
        "\n",
        "def update_status_capacity(airport_req_dict, num_airports, cap_dem_dict, requests_full):\n",
        "    #Them cot cap_status o init:\n",
        "    for i in range(num_airports):\n",
        "        for k in range(len(airport_req_dict['req_{}'.format(i)])):\n",
        "            _time_slot = int(airport_req_dict['req_{}'.format(i)][k][1]) * int(airport_req_dict['req_{}'.format(i)][k][13]) + int(airport_req_dict['req_{}'.format(i)][k][9]) * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
        "            _date_seq = airport_req_dict['req_{}'.format(i)][k][4] * int(airport_req_dict['req_{}'.format(i)][k][13]) + airport_req_dict['req_{}'.format(i)][k][11] * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
        "            if all(x >= 0 for x in cap_dem_dict['req_{}'.format(i)][_time_slot, _date_seq]):\n",
        "                #print(self.cap_dem_arr[_time_slot, _date_seq])\n",
        "                airport_req_dict['req_{}'.format(i)][k][8] = 0\n",
        "                airport_req_dict['req_{}'.format(i)][k][12] = 0\n",
        "            else:\n",
        "                if airport_req_dict['req_{}'.format(i)][k][13] == 1:\n",
        "                    airport_req_dict['req_{}'.format(i)][k][8] = 1\n",
        "                    _indices = np.where(requests_full[:, 0] == airport_req_dict['req_{}'.format(i)][k][0])\n",
        "                    requests_full[_indices, 8] = 1\n",
        "                else:\n",
        "                    airport_req_dict['req_{}'.format(i)][k][12] = 1\n",
        "                    _indices = np.where(requests_full[:, 0] == airport_req_dict['req_{}'.format(i)][k][0])\n",
        "                    requests_full[_indices, 12] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TwoAirportSchedEnv(gym.Env):\n",
        "    def __init__(self, number_of_actions, number_of_requests, num_airports, cap_per_airport_arr):\n",
        "        #TODO: add agents to array - Roman\n",
        "        self.agents=[]\n",
        "        \n",
        "        super(TwoAirportSchedEnv, self).__init__()\n",
        "        self.number_of_actions = int(number_of_actions)\n",
        "        self.number_of_requests = number_of_requests\n",
        "        self.num_airports = num_airports\n",
        "        #self.number_of_days = number_of_days\n",
        "        self.cap_per_airport_arr = cap_per_airport_arr\n",
        "        self.cap_dict = generate_deterministic_capacity_dict(self.num_airports, self.cap_per_airport_arr)\n",
        "        #self.generate_scenario()\n",
        "        #update the code to add generate scenario \n",
        "        self.requests_full, self.airport_req_dict, self._belong_airport_dict, self.pot_dem_dict, self.cap_dem_dict = generate_scenario(number_of_requests, num_airports, cap_dict = self.cap_dict)\n",
        "        #to generate action:\n",
        "        self.action_space = spaces.Discrete(self.number_of_actions)\n",
        "        self.observation_space = spaces.Box(low= -np.inf, high= np.inf, shape=(7,), dtype=float)\n",
        "\n",
        "        #cap_dem_dict_flat = flatten_cap_dem_dict(cap_dem_dict, num_airports)\n",
        "        #_generate = True\n",
        "        update_status_capacity(self.airport_req_dict, self.num_airports, self.cap_dem_dict, self.requests_full)\n",
        "        #for i in range(len(self.requests_full)):\n",
        "        #  #print(self.requests_full[i][8], self.requests_full[i][12])\n",
        "        \n",
        "        _exceed_cap = 0         \n",
        "        while _exceed_cap == 0:\n",
        "            self.requests_full, self.airport_req_dict, self._belong_airport_dict, self.pot_dem_dict, self.cap_dem_dict = generate_scenario(number_of_requests = self.number_of_requests, num_airports = self.num_airports, cap_dict = self.cap_dict)\n",
        "            self.cap_dem_dict_flat = flatten_cap_dem_dict(self.cap_dem_dict, self.num_airports)\n",
        "            for i in range(num_airports):\n",
        "                _exceed_cap = _exceed_cap + (min(self.cap_dem_dict_flat['req_{}'.format(i)]))\n",
        "        \n",
        "\n",
        "        update_status_capacity(self.airport_req_dict, self.num_airports, self.cap_dem_dict, self.requests_full)\n",
        "        self.num_step = 0\n",
        "        \n",
        "        #to choose the request that will be checked\n",
        "        self.get_req()\n",
        "\n",
        "        self.dep_time_slot = self.chosen_req[1]\n",
        "        self.original_requests = self.requests_full\n",
        "    \n",
        "    def action_mapping(self, action, number_of_actions):\n",
        "        mid_point = (number_of_actions - 1) // 2\n",
        "        return action - mid_point\n",
        "    \n",
        "    #added get request to know which is the request we are going to move at this step\",\n",
        "    def get_req(self):\n",
        "        violate_set=get_violate_id_set(self.airport_req_dict, num_airports)\n",
        "        _violate_index = random.choice(violate_set)\n",
        "        self.chosen_req = self.requests_full[self.requests_full[:,0] == _violate_index][0]\n",
        "    \n",
        "    #need to check arrival time or change the variable to check_outbound(arv) and chec_outbound(dep)\n",
        "    def check_outbound(self, action):\n",
        "        dep_time_slot = self.chosen_req[1]\n",
        "        arv_time_slot = self.chosen_req[9]\n",
        "\n",
        "        outbound = False\n",
        "\n",
        "        new_dep_time_slot = dep_time_slot + action\n",
        "        new_arv_time_slot = arv_time_slot + action\n",
        "\n",
        "        if (new_dep_time_slot < 0) or (new_dep_time_slot > 287) or (new_arv_time_slot < 0) or (new_arv_time_slot > 287):\n",
        "            outbound = True\n",
        "\n",
        "        return outbound\n",
        "    \n",
        "    def dep_or_arv(self):\n",
        "        pass\n",
        "\n",
        "    def update_dem(self, dep_airport, arv_airport, time_slot_dep, time_slot_arv, new_time_slot_dep, new_time_slot_arv, date_seq_dep, date_seq_arv):\n",
        "        # Increment demand for the new time slot for both departure and arrival airports\n",
        "        self.pot_dem_dict['req_{}'.format(dep_airport)][new_time_slot_dep, date_seq_dep] += 1\n",
        "        self.pot_dem_dict['req_{}'.format(arv_airport)][new_time_slot_arv, date_seq_arv] += 1\n",
        "\n",
        "        # Decrease demand for the initial time slot for both departure and arrival airports\n",
        "        self.pot_dem_dict['req_{}'.format(dep_airport)][time_slot_dep, date_seq_dep] -= 1\n",
        "        self.pot_dem_dict['req_{}'.format(arv_airport)][time_slot_arv, date_seq_arv] -= 1\n",
        "\n",
        "    def update_cap_dem(self):\n",
        "        for airport in range(self.num_airports):\n",
        "            cap_key = 'req_{}'.format(airport)\n",
        "            dem_key = 'req_{}'.format(airport)\n",
        "            if cap_key not in self.cap_dict:\n",
        "                raise KeyError(f\"'{cap_key}' not found in cap_dict. Available keys: {list(self.cap_dict.keys())}\")\n",
        "            self.cap_dem_dict[cap_key] = self.cap_dict[cap_key] - self.pot_dem_dict[dem_key]\n",
        "\n",
        "    # Need to validate\n",
        "    def update_violate_set(curr_violate, not_violate_update, violate_update):\n",
        "        curr_violate = set(curr_violate)\n",
        "        for req_index in not_violate_update:\n",
        "            curr_violate.remove(req_index)\n",
        "        for req_index in violate_update:\n",
        "            curr_violate.add(req_index) \n",
        "        curr_violate = list(curr_violate)\n",
        "        return curr_violate \n",
        "    \n",
        "    # Based on agent's actions\n",
        "    def take_action(self, action_dep, action_arv):\n",
        "        #Check if actions match\n",
        "        if action_dep != action_arv:\n",
        "            return 0\n",
        "        else:\n",
        "            return action_dep\n",
        "    \n",
        "    def when_take_action(self, action):\n",
        "        # num_actions = self.number_of_actions\n",
        "        # # Convert the discrete action to your desired action value\n",
        "        # real_action = self.action_mapping(action, num_actions)        \n",
        "\n",
        "        _index = self.chosen_req[0]\n",
        "        time_slot_dep = self.chosen_req[1]\n",
        "        time_slot_arv = self.chosen_req[9]\n",
        "        time_slot_arv = int(time_slot_arv)\n",
        "        _dep_airport = self.chosen_req[5].index(1.0)\n",
        "        _arv_airport = self.chosen_req[6].index(1.0)\n",
        "        _date_seq_dep = self.chosen_req[4]\n",
        "        _date_seq_arv = self.chosen_req[11]\n",
        "        _start_date_dep = self.chosen_req[2]\n",
        "        _start_date_arv = self.chosen_req[10]\n",
        "        _num_weeks = self.chosen_req[3]\n",
        "        # new_time_slot_dep = time_slot_dep + real_action\n",
        "        new_time_slot_dep = time_slot_dep + action\n",
        "        # new_time_slot_arv = time_slot_arv + real_action\n",
        "        new_time_slot_arv = time_slot_arv + action\n",
        "        new_time_slot_arv = int(new_time_slot_arv)\n",
        "        new_date_seq_dep = _date_seq_dep\n",
        "        new_date_seq_arv = _date_seq_arv\n",
        "\n",
        "        outbound = self.check_outbound(action)\n",
        "\n",
        "        if not outbound:\n",
        "            pass\n",
        "            \n",
        "        elif outbound:\n",
        "            # Adjust the departure time slot as needed\n",
        "            if new_time_slot_dep < 0:\n",
        "                new_time_slot_dep = 287  # Move to the last time slot of the previous day\n",
        "                new_start_date_dep = _start_date_dep - 1\n",
        "                new_date_seq_dep = get_date_seq(new_start_date_dep, _num_weeks)\n",
        "            elif new_time_slot_dep > 287:\n",
        "                new_time_slot_dep = 0  # Move to the first time slot of the next day\n",
        "                new_start_date_dep = _start_date_dep + 1\n",
        "                new_date_seq_dep = get_date_seq(new_start_date_dep, _num_weeks)\n",
        "            # Adjust the departure time slot as needed\n",
        "            if new_time_slot_arv < 0:\n",
        "                # Assume that we only move by max one slot for a timeslot change\n",
        "                new_time_slot_arv = 287  # Move to the last time slot of the previous day\n",
        "                new_time_slot_arv = int(new_time_slot_arv)\n",
        "                new_start_date_arv = _start_date_arv - 1\n",
        "                new_date_seq_arv = get_date_seq(new_start_date_arv, _num_weeks)\n",
        "            elif new_time_slot_dep > 287:\n",
        "                # Assume that we only move by max one slot for a timeslot change\n",
        "                new_time_slot_dep = 0  # Move to the first time slot of the next day\n",
        "                new_time_slot_arv = int(new_time_slot_arv)\n",
        "                new_start_date_arv = _start_date_arv + 1\n",
        "                new_date_seq_arv = get_date_seq(new_start_date_arv, _num_weeks)\n",
        "\n",
        "        else:\n",
        "            print('Problem with check outbound!')\n",
        "            \n",
        "        # Update the request for both departure and arrival time slots and dates\n",
        "        self.requests_full[self.requests_full[:, 0] == _index][:, 1] = new_time_slot_dep\n",
        "        self.requests_full[self.requests_full[:, 0] == _index][:, 9] = new_time_slot_arv\n",
        "        # self.requests_full[self.requests_full[:, 0] == _index][:, 4] = new_date_seq_dep\n",
        "        # self.requests_full[self.requests_full[:, 0] == _index][:, 11] = new_date_seq_arv\n",
        "        _index_matching = np.where(self.requests_full[:, 0] == _index)[0][0]\n",
        "        self.requests_full[_index_matching, 4] = new_date_seq_dep\n",
        "        self.requests_full[_index_matching, 11] = new_date_seq_arv\n",
        "\n",
        "        # Update the airport request dict\n",
        "        self.airport_req_dict['req_{}'.format(_dep_airport)][self.airport_req_dict['req_{}'.format(_dep_airport)][:, 0] == _index][:, 1] = new_time_slot_dep\n",
        "        self.airport_req_dict['req_{}'.format(_dep_airport)][self.airport_req_dict['req_{}'.format(_dep_airport)][:, 0] == _index][:, 9] = new_time_slot_arv\n",
        "        self.airport_req_dict['req_{}'.format(_arv_airport)][self.airport_req_dict['req_{}'.format(_arv_airport)][:, 0] == _index][:, 1] = new_time_slot_dep\n",
        "        self.airport_req_dict['req_{}'.format(_arv_airport)][self.airport_req_dict['req_{}'.format(_arv_airport)][:, 0] == _index][:, 9] = new_time_slot_arv\n",
        "\n",
        "        # Update demand for the new time slots\n",
        "        self.update_dem(_dep_airport, _arv_airport, time_slot_dep, time_slot_arv, new_time_slot_dep, new_time_slot_arv, new_date_seq_dep, new_date_seq_arv)\n",
        "        \n",
        "        # Update cap_dem \n",
        "        self.update_cap_dem()\n",
        "\n",
        "        # Update status capacity after the cap_dem table is updated\n",
        "        update_status_capacity(self.airport_req_dict, self.num_airports, self.cap_dem_dict, self.requests_full)\n",
        "\n",
        "    def step(self, action): \n",
        "        _num_weeks = self.chosen_req[3]\n",
        "        self.when_take_action(action)\n",
        "        outbound = self.check_outbound(action)\n",
        "\n",
        "        # Reward part:\n",
        "        if action != 0:\n",
        "            \n",
        "            local_reward = 0\n",
        "            if outbound:\n",
        "                # local_reward = -1\n",
        "                local_reward = 0.1*(-abs(action)*0.5*_num_weeks)\n",
        "            else:\n",
        "                local_reward = 0.1*(-abs(action)*0.5*_num_weeks) #TODO change if increase number of actions\n",
        "            \n",
        "            self.num_step += 1\n",
        "            done = False\n",
        "            if self.chosen_req[8] == 0 and self.chosen_req[12] == 0:\n",
        "                done = True\n",
        "                obs = np.zeros((self.number_of_actions + 1,))\n",
        "                global_reward = 10\n",
        "\n",
        "            elif self.num_step == self.number_of_requests*5:\n",
        "                done = True\n",
        "                obs = np.zeros((self.number_of_actions + 1,))\n",
        "                negative_sum = -10\n",
        "                for value in self.cap_dem_dict.values():\n",
        "                    # Assuming each value is a numeric value or a numpy array\n",
        "                    # If it's a numpy array, you can sum all negative values directly using numpy\n",
        "                    if isinstance(value, np.ndarray):\n",
        "                        negative_sum -= np.sum(value[value < 0])\n",
        "                    else:\n",
        "                        # If it's a single numeric value, just check if it's negative\n",
        "                        if value < 0:\n",
        "                            negative_sum -= value\n",
        "                global_reward = negative_sum\n",
        "\n",
        "            else:\n",
        "                global_reward = 0\n",
        "                obs = self._next_observation()\n",
        "                # obs = np.zeros((self.number_of_actions + 1,))\n",
        "\n",
        "            reward_time_step = -0.5\n",
        "        \n",
        "\n",
        "        else:\n",
        "            reward_time_step = -0.5\n",
        "            local_reward = 0\n",
        "            global_reward = 0\n",
        "\n",
        "        total_reward = float(local_reward + global_reward + reward_time_step)\n",
        "    \n",
        "        return obs, total_reward, done, {}\n",
        "    \n",
        "    def _next_observation(self):\n",
        "        self.get_req()\n",
        "        _ts_dep = self.chosen_req[1]\n",
        "        _ts_arv = self.chosen_req[9]\n",
        "        _num_of_weeks = self.chosen_req[3]\n",
        "        _date_seq_dep = self.chosen_req[4]\n",
        "        _date_seq_arv = self.chosen_req[11]\n",
        "        _dep_airport = self.chosen_req[5].index(1.0)\n",
        "        _arv_airport = self.chosen_req[6].index(1.0)\n",
        "        cap_dem_arr_dep = self.cap_dem_dict['req_{}'.format(_dep_airport)]\n",
        "        cap_dem_arr_arv = self.cap_dem_dict['req_{}'.format(_arv_airport)]\n",
        "        _cap_dem_dep = cap_dem_arr_dep[:, _date_seq_dep].copy()\n",
        "        _cap_dem_arv = cap_dem_arr_arv[:, _date_seq_arv].copy()\n",
        "\n",
        "        _obs_min_arr_dep = full_obs(_cap_dem_dep, self.number_of_actions)\n",
        "        _obs_min_arr_arr = full_obs(_cap_dem_arv, self.number_of_actions)\n",
        "        _obs_time_slot_related_dep = list(range(int(_ts_dep), int(_ts_dep + self.number_of_actions), 1))\n",
        "        _obs_time_slot_related_arv = list(range(int(_ts_arv), int(_ts_arv + self.number_of_actions), 1))\n",
        "        _cap_dem_obs_dep = _obs_min_arr_dep[_obs_time_slot_related_dep]\n",
        "        _cap_dem_obs_arv = _obs_min_arr_arr[_obs_time_slot_related_arv]\n",
        "\n",
        "        # Appending _cap_dem_obs_arv to _cap_dem_obs_dep\n",
        "        self.obs = np.append(_cap_dem_obs_dep, _cap_dem_obs_arv)\n",
        "        # append _num_of_weeks to the result of the above, do the following:\n",
        "        self.obs = np.append(self.obs, _num_of_weeks)\n",
        "        \n",
        "        return self.obs\n",
        "\n",
        "    def reset(self):                \n",
        "        generate_scenario(self.number_of_requests, self.num_airports, cap_dict = self.cap_dict)\n",
        "        _dep_airport = self.chosen_req[5].index(1.0)\n",
        "        _arv_airport = self.chosen_req[6].index(1.0)\n",
        "        cap_dem_arr_dep = self.cap_dem_dict['req_{}'.format(_dep_airport)]\n",
        "        cap_dem_arr_arv = self.cap_dem_dict['req_{}'.format(_arv_airport)]\n",
        "        \n",
        "        _cap_dem_flat_dep = cap_dem_arr_dep.flatten()\n",
        "        _cap_dem_flat_arv = cap_dem_arr_arv.flatten()\n",
        "\n",
        "        while (min(_cap_dem_flat_dep) >= 0 or min(_cap_dem_flat_arv) >= 0):\n",
        "            generate_scenario(self.number_of_requests, self.num_airports, cap_dict = self.cap_dict)\n",
        "            _cap_dem_flat_dep = cap_dem_arr_dep.flatten()\n",
        "            _cap_dem_flat_arv = cap_dem_arr_arv.flatten()\n",
        "        \n",
        "        update_status_capacity(self.airport_req_dict, self.num_airports, self.cap_dem_dict, self.requests_full)\n",
        "        print('Number of violation for dep: ', len(_cap_dem_flat_dep[_cap_dem_flat_dep < 0]))\n",
        "        print('Number of violation for arv: ', len(_cap_dem_flat_arv[_cap_dem_flat_arv < 0]))\n",
        "\n",
        "        self.num_step = 0        \n",
        "        return self._next_observation()\n",
        "    \n",
        "    # Need to validate\n",
        "    def eval(self):\n",
        "        _dep_airport = self.chosen_req[5].index(1.0)\n",
        "        _arv_airport = self.chosen_req[6].index(1.0)\n",
        "        _initial_cap_dem_dict = {}\n",
        "        _initial_pot_dem_dict = get_initial_pot_dem_per_airport(self.airport_req_dict, self.num_airports)\n",
        "        for airport in range(self.num_airports):\n",
        "            cap_key = 'req_{}'.format(airport)\n",
        "            dem_key = 'req_{}'.format(airport)\n",
        "            _initial_cap_dem_dict[cap_key] = self.cap_dict[cap_key] - _initial_pot_dem_dict[dem_key]\n",
        "\n",
        "        _initial_cap_dem_dep = self.cap_dem_dict['req_{}'.format(_dep_airport)]\n",
        "        _initial_cap_dem_flat_dep = _initial_cap_dem_dep.flatten()\n",
        "        _initial_violate_dep = len(_initial_cap_dem_flat_dep[_initial_cap_dem_flat_dep < 0])\n",
        "        print('Initial violation of departure is: ', _initial_violate_dep)\n",
        "        _initial_cap_dem_arv = self.cap_dem_dict['req_{}'.format(_arv_airport)]\n",
        "        _initial_cap_dem_flat_arv = _initial_cap_dem_arv.flatten()\n",
        "        _initial_violate_arv = len(_initial_cap_dem_flat_arv[_initial_cap_dem_flat_arv < 0])\n",
        "        print('Initial violation of arrival is: ', _initial_violate_arv)\n",
        "\n",
        "        cap_dem_arr_dep = self.cap_dem_dict['req_{}'.format(_dep_airport)]\n",
        "        cap_dem_arr_arv = self.cap_dem_dict['req_{}'.format(_arv_airport)]\n",
        "        _final_cap_dem_flat_dep = cap_dem_arr_dep.flatten()\n",
        "        _final_cap_dem_flat_arv = cap_dem_arr_arv.flatten()\n",
        "        _final_violate_dep = len(_final_cap_dem_flat_dep[_final_cap_dem_flat_dep < 0])\n",
        "        _final_violate_arv = len(_final_cap_dem_flat_arv[_final_cap_dem_flat_arv < 0])\n",
        "        print('Final violation of departure is: ', _final_violate_dep)\n",
        "        print('Final violation of arrival is: ', _final_violate_arv)\n",
        "\n",
        "        _total_sched_delay_dep = sum(abs(self.original_requests[:,1] - self.requests_full[:,1])* self.original_requests[:,3])\n",
        "        print('Total schedule delay of departure is: ', _total_sched_delay_dep)\n",
        "        _total_sched_delay_arv = sum(abs(self.original_requests[:,9] - self.requests_full[:,9])* self.original_requests[:,3])\n",
        "        print('Total schedule delay of arrival is: ', _total_sched_delay_arv)\n",
        "\n",
        "        _max_shift_dep = max(abs(self.original_requests[:,1] - self.requests_full[:,1]))\n",
        "        print('Max shift of departure: ', _max_shift_dep)\n",
        "        _max_shift_arv = max(abs(self.original_requests[:,9] - self.requests_full[:,9]))\n",
        "        print('Max shift of arrival: ', _max_shift_arv)\n",
        "\n",
        "        _unaccom_req_dep = len(self.requests_full[self.requests_full[:,8] == 1])\n",
        "        print('Number of unaccommodate departure requests: ', _unaccom_req_dep)\n",
        "        _unaccom_req_arv = len(self.requests_full[self.requests_full[:,12] == 1])\n",
        "        print('Number of unaccommodate arrival requests: ', _unaccom_req_arv)\n",
        "\n",
        "        return _initial_violate_dep, _initial_violate_arv, _final_violate_dep, _final_violate_arv, _total_sched_delay_dep, _total_sched_delay_arv, _max_shift_dep, _max_shift_arv, _unaccom_req_dep, _unaccom_req_arv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIi_V1ws2YkD",
        "outputId": "71f5fcdf-9c01-4967-b007-fead0d8edc8d"
      },
      "outputs": [],
      "source": [
        "# Initialize Two Airport Scheduler environment\n",
        "env = TwoAirportSchedEnv(number_of_actions=3, number_of_requests=15000, num_airports=3, cap_per_airport_arr= [9,9,9])\n",
        "# env.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "agj--eUZ2uUg"
      },
      "outputs": [],
      "source": [
        "# Define Neural Network for Q Network\n",
        "class QNetwork(nn.Module):\n",
        "    # Initilize parameters to build model\n",
        "    def __init__(self, state_size, action_size, seed):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(state_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, action_size)\n",
        "    \n",
        "    # Build a network that maps state to action values\n",
        "    def forward(self, state):\n",
        "        x = self.fc1(state)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        return self.fc3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qdnFz3Co39xr"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters\n",
        "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
        "BATCH_SIZE = 64         # minibatch size\n",
        "GAMMA = 0.99            # discount factor\n",
        "TAU = 1e-3              # for soft update of target parameters\n",
        "LR = 5e-2               # learning rate \n",
        "UPDATE_EVERY = 4        # how often to update the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lmaowp_I4AUW"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kKW2OjYp4CQ0"
      },
      "outputs": [],
      "source": [
        "# Define the agent\n",
        "class Agent():\n",
        "    # Initialize the Agent object\n",
        "    def __init__(self, state_size, action_size, seed):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "        # Q-Network\n",
        "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
        "\n",
        "        # Replay memory\n",
        "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
        "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
        "        self.t_step = 0\n",
        "    \n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "        \n",
        "        # Learn every UPDATE_EVERY time steps.\n",
        "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
        "        if self.t_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) > BATCH_SIZE:\n",
        "                experiences = self.memory.sample()\n",
        "                self.learn(experiences, GAMMA)\n",
        "\n",
        "    # Function to return actions for the given state based on the current policy\n",
        "    def act(self, state, eps=0.):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        self.qnetwork_local.eval()\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork_local(state)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        # change this to just take random action and return the action after mapping\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.random() > eps:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            return random.choice(np.arange(self.action_size))\n",
        "\n",
        "    # Update the value parameters based on the given batch of experience tuples\n",
        "    def learn(self, experiences, gamma):\n",
        "\n",
        "        # Obtain random minibatch of tuples from D\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        # Compute and minimize the loss\n",
        "        # Extract next maximum estimated value from target network\n",
        "        q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        # Calculate target value from bellman equation\n",
        "        q_targets = rewards + gamma * q_targets_next * (1 - dones)\n",
        "        # Calculate expected value from local network\n",
        "        q_expected = self.qnetwork_local(states).gather(1, actions)\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss = F.mse_loss(q_expected, q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Update the target network\n",
        "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
        "\n",
        "    def soft_update(self, local_model, target_model, tau):\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YbeCCM6_4FHr"
      },
      "outputs": [],
      "source": [
        "# Define the Replay Buffer\n",
        "class ReplayBuffer:\n",
        "    # Initialize the Replay Buffer\n",
        "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=buffer_size)  \n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.seed = random.seed(seed)\n",
        "    \n",
        "    # Add a new experience\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(e)\n",
        "    \n",
        "    # Randomly sample a batch of experiences from memory\n",
        "    def sample(self):\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "\n",
        "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
        "  \n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.24.3'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "numpy.version.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4dZOT-14HtA",
        "outputId": "e9518f1a-0798-4423-db24-b670d4900ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([-0.00931454,  1.4230326 , -0.46551317,  0.25641942,  0.00889623,\n",
            "        0.06900696,  0.        ,  0.        ], dtype=float32), 1.1759634873409948, False, False, {})\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "expected np.ndarray (got numpy.float32)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[36], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m scores\n\u001b[1;32m     31\u001b[0m agent \u001b[39m=\u001b[39m Agent(state_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, action_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m scores \u001b[39m=\u001b[39m dqn()\n",
            "Cell \u001b[0;32mIn[36], line 11\u001b[0m, in \u001b[0;36mdqn\u001b[0;34m(n_episodes, max_t, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[1;32m      8\u001b[0m score \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_t):\n\u001b[1;32m     10\u001b[0m     \u001b[39m# print(state)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mact(state[\u001b[39m0\u001b[39m], eps)\n\u001b[1;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(env\u001b[39m.\u001b[39mstep(action))\n\u001b[1;32m     13\u001b[0m     next_state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)[:\u001b[39m4\u001b[39m]\n",
            "Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mAgent.act\u001b[0;34m(self, state, eps)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mact\u001b[39m(\u001b[39mself\u001b[39m, state, eps\u001b[39m=\u001b[39m\u001b[39m0.\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(state)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqnetwork_local\u001b[39m.\u001b[39meval()\n\u001b[1;32m     35\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
            "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got numpy.float32)"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
        "    scores = []                        # list containing scores from each episode\n",
        "    scores_window = deque(maxlen=100)  # last 100 scores\n",
        "    eps = eps_start                    # initialize epsilon\n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "        state = env.reset()\n",
        "        score = 0\n",
        "        for t in range(max_t):\n",
        "            action = agent.act(state, eps)\n",
        "            #env.combine_action\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            score += reward\n",
        "            if done:\n",
        "                break \n",
        "        scores_window.append(score)       # save most recent score\n",
        "        scores.append(score)              # save most recent score\n",
        "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
        "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
        "        if i_episode % 100 == 0:\n",
        "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
        "        if np.mean(scores_window)>=200.0:\n",
        "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
        "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
        "            break\n",
        "    return scores\n",
        "\n",
        "agent1 = Agent(state_size=8, action_size=4, seed=0)\n",
        "agent2\n",
        "agent3\n",
        "scores = dqn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "yTXjha4P4NGF",
        "outputId": "23695f85-3808-49d7-b976-3ef59d209c9c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the learning progress\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(len(scores)), scores)\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episode #')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
