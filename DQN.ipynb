{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random \n",
    "from collections import namedtuple, deque \n",
    "\n",
    "##Importing the model (function approximator for Q-table)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import mps\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import random\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import stable_baselines3\n",
    "from stable_baselines3.sac.policies import MlpPolicy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def get_truncated_normal(mean, sd, low, upp):\n",
    "    return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "\n",
    "def get_date_seq(start_date_arr, num_of_weeks_arr): #start_date index 2, num_of_weeks index 3\n",
    "    date_seq_arr = np.empty(shape=(len(start_date_arr),), dtype='object')\n",
    "    for i in range(len(date_seq_arr)):\n",
    "        date_seq_arr[i] = list(range(int(start_date_arr[i]), int(start_date_arr[i]) + int(num_of_weeks_arr[i])*7, 7))\n",
    "    return date_seq_arr\n",
    "\n",
    "\n",
    "def full_obs(_cap_dem_chosen_req, number_of_actions):\n",
    "    _obs_min_arr = np.full((288+number_of_actions-1, ), 0)\n",
    "    for i in range(len(_cap_dem_chosen_req)):\n",
    "        _obs_min_arr[i+int((number_of_actions-1)/2)] = min(_cap_dem_chosen_req[i])\n",
    "    return _obs_min_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode_airport(airport, num_airports):\n",
    "    encoding = np.zeros(num_airports)\n",
    "    encoding[airport] = 1\n",
    "    return encoding\n",
    "\n",
    "# Example usage\n",
    "num_airports = 3\n",
    "airport1 = 0\n",
    "airport2 = 1\n",
    "airport3 = 2\n",
    "\n",
    "encoded_airport1 = one_hot_encode_airport(airport1, num_airports)\n",
    "encoded_airport2 = one_hot_encode_airport(airport2, num_airports)\n",
    "encoded_airport3 = one_hot_encode_airport(airport3, num_airports)\n",
    "\n",
    "print(encoded_airport1)\n",
    "print(encoded_airport2)\n",
    "print(encoded_airport3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_info_arv(requests):\n",
    "    ts_arv = np.empty(shape=(len(requests),), dtype='object')\n",
    "    start_date_arv = np.empty(shape=(len(requests),), dtype='object')\n",
    "    #date_seq_arv = np.empty(shape=(len(requests),), dtype='object')\n",
    "    for i in range(len(requests)):\n",
    "        ts_arv[i] = requests[i][1] + requests[i][7]/5\n",
    "        if ts_arv[i] > 287:\n",
    "            ts_arv[i] = ts_arv[i] - 287\n",
    "            start_date_arv[i] = requests[i][2] + 1\n",
    "        else:\n",
    "            start_date_arv[i] = requests[i][2]\n",
    "    date_seq_arv = get_date_seq(start_date_arv, requests[:, 3])\n",
    "    return ts_arv, start_date_arv, date_seq_arv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scenario(number_of_requests, num_airports, cap_dict):\n",
    "    \n",
    "    #number_of_requests = 15000\n",
    "    ts_72 = get_truncated_normal(mean=72, sd=12, low=0, upp=287).rvs(int(round(number_of_requests/2)))\n",
    "    ts_72 = np.round(ts_72)\n",
    "\n",
    "    ts_216 = get_truncated_normal(mean=216, sd=12, low=0, upp=287).rvs(int(round(number_of_requests/2)))\n",
    "    ts_216 = np.round(ts_216)\n",
    "\n",
    "    ts_dep = np.concatenate((ts_72, ts_216))\n",
    "    ts_dep = ts_dep.astype(int)\n",
    "\n",
    "    #Generate start date:\n",
    "\n",
    "    start_date_dep = np.random.randint(low = 0, high=146, size=number_of_requests) #146 because period is 182 days and we consider series which span at least 5 weeks (+35 days)\n",
    "\n",
    "    #Generate number of weeks:\n",
    "\n",
    "    _max_day = np.full(number_of_requests, 182 - 1)\n",
    "\n",
    "    _remaining_days = _max_day - start_date_dep\n",
    "\n",
    "    _max_num_of_weeks = _remaining_days // 7\n",
    "\n",
    "    num_of_weeks = np.random.randint(5, _max_num_of_weeks + 1)\n",
    "\n",
    "    #Generate index for requests:\n",
    "\n",
    "    index = np.array(list(range(number_of_requests)))\n",
    "\n",
    "    #Generate origin (0 and 1 are two considered origin airports, 2 represent other airports, encoded in one-hot vector):\n",
    "\n",
    "    #num_airports = 3\n",
    "    origin_airport = np.empty(shape=(number_of_requests,), dtype='object')\n",
    "    destination_airport = np.empty(shape=(number_of_requests,), dtype='object')\n",
    "    for i in range(number_of_requests):\n",
    "        _org_airport = one_hot_encode_airport(random.randint(0,2), num_airports)\n",
    "        _org_airport_list = _org_airport.tolist()\n",
    "        origin_airport[i] = _org_airport_list\n",
    "        #Generate destination (the destination will be different with the origin):\n",
    "        _dest_airport = _org_airport.copy()\n",
    "        while np.array_equal(_dest_airport, _org_airport):\n",
    "            np.random.shuffle(_dest_airport)\n",
    "        _dest_airport_list = _dest_airport.tolist()\n",
    "        destination_airport[i] = _dest_airport_list\n",
    "\n",
    "    #Generate flying time (assume between airport 0 and 1 is 2 hour, 0 to 2 and 1 to 2 is arbitrary):\n",
    "\n",
    "    fly_time = np.empty(shape=(number_of_requests,), dtype='object')\n",
    "    for i in range (number_of_requests):\n",
    "        if origin_airport[i] == list([1.0, 0.0, 0.0]) and destination_airport[i] == list([0.0, 1.0, 0.0]):\n",
    "            fly_time[i] = 120\n",
    "        elif origin_airport[i] == list([1.0, 0.0, 0.0]) and destination_airport[i] == list([0.0, 0.0, 1.0]):\n",
    "            fly_time[i] = random.choice([60, 120, 180])\n",
    "        elif origin_airport[i] == list([0.0, 1.0, 0.0]) and destination_airport[i] == list([1.0, 0.0, 0.0]):\n",
    "            fly_time[i] = 120\n",
    "        elif origin_airport[i] == list([0.0, 1.0, 0.0]) and destination_airport[i] == list([0.0, 0.0, 1.0]):\n",
    "            fly_time[i] = random.choice([60, 120, 180])\n",
    "        elif origin_airport[i] == list([0.0, 0.0, 1.0]) and destination_airport[i] == list([1.0, 0.0, 0.0]):\n",
    "            fly_time[i] = random.choice([60, 120, 180])\n",
    "        elif origin_airport[i] == list([0.0, 0.0, 1.0]) and destination_airport[i] == list([0.0, 1.0, 0.0]):\n",
    "            fly_time[i] = random.choice([60, 120, 180])\n",
    "\n",
    "    #Get date sequence (date seq is actually a list):\n",
    "\n",
    "    date_seq_dep = get_date_seq(start_date_dep, num_of_weeks)\n",
    "\n",
    "    #Generate status cap:\n",
    "\n",
    "    status_cap_dep = np.full((number_of_requests,), 0)\n",
    "    status_cap_arv = np.full((number_of_requests,), 0)\n",
    "    \n",
    "\n",
    "    requests = np.stack((index, ts_dep, start_date_dep, num_of_weeks, date_seq_dep, origin_airport, destination_airport, fly_time, status_cap_dep), axis=1)\n",
    "\n",
    "    #Generate full info for the arv side:\n",
    "\n",
    "    ts_arv, start_date_arv, date_seq_arv = generate_info_arv(requests)\n",
    "\n",
    "    #pseudo_belong_dep = np.full((number_of_requests,), 0)\n",
    "    #pseudo_belong_arv = np.full((number_of_requests,), 0)\n",
    "    \n",
    "    # Define requests_full as dtype object\n",
    "    # requests_full = np.stack((index, ts_dep, start_date_dep, num_of_weeks, date_seq_dep, origin_airport, destination_airport, fly_time, status_cap_dep, ts_arv, start_date_arv, date_seq_arv, status_cap_arv), axis=1)\n",
    "    num_entries = len(index)  # Given that 'index' is defined using np.array(list(range(number_of_requests)))\n",
    "    # Create an empty array of the desired shape with dtype=object\n",
    "    requests_full = np.empty((num_entries, 13), dtype=object)\n",
    "    # Fill the array\n",
    "    data = [index, ts_dep, start_date_dep, num_of_weeks, date_seq_dep, origin_airport, destination_airport, fly_time, status_cap_dep, ts_arv, start_date_arv, date_seq_arv, status_cap_arv]\n",
    "    for i, column_data in enumerate(data):\n",
    "        requests_full[:, i] = column_data\n",
    "\n",
    "    # airport_req_dict: A dictionary where each key corresponds to a specific airport's requirements. \n",
    "    # The key format is 'req_i', where i is the index of the airport. \n",
    "    # The value for each key is a numpy array, with each row representing a request and the columns containing different attributes of that request.\n",
    "    airport_req_dict, _belong_airport_dict = get_airport_req_dict(requests_full, num_airports)\n",
    "\n",
    "    pot_dem_dict = get_initial_pot_dem_per_airport(airport_req_dict, num_airports)\n",
    "\n",
    "    cap_dem_dict = get_cap_dem_dict(num_airports, cap_dict, pot_dem_dict)\n",
    "\n",
    "    return requests_full, airport_req_dict, _belong_airport_dict, pot_dem_dict, cap_dem_dict\n",
    "\n",
    "    #Generate capacity:\n",
    "\n",
    "    #cap_arr = np.full((288, 182), 20)\n",
    "\n",
    "    #Create final_sched:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_violate_id_set(airport_req_dict, num_airports):\n",
    "    violate_set = [] #(1: id, 2: airport, 3: dep, 4: arv)\n",
    "    for i in range(num_airports):\n",
    "        mask = ((airport_req_dict['req_{}'.format(i)][:, 8] + airport_req_dict['req_{}'.format(i)][:, 12]) >= 1)\n",
    "        _id_violate_per_airport = airport_req_dict['req_{}'.format(i)][mask, :][:,0]\n",
    "        violate_set.append(_id_violate_per_airport)\n",
    "    violate_set = np.concatenate(violate_set, axis=0)\n",
    "    violate_set = np.unique(violate_set)\n",
    "    return violate_set\n",
    "\n",
    "def get_violate_id_set_req_full(requests_full):\n",
    "    mask = ((requests_full[:, 8] + requests_full[:, 12]) >= 1)\n",
    "    violate_set_req_full = requests_full[mask, :][:,0]\n",
    "    return violate_set_req_full\n",
    "\n",
    "def get_req(violate_set, requests_full):\n",
    "    # if not violate_set:\n",
    "    #     raise ValueError(\"The provided violate_set is empty!\")\n",
    "    _violate_index = random.choice(violate_set)\n",
    "    chosen_req = requests_full[requests_full[:,0] == _violate_index]\n",
    "    return chosen_req\n",
    "\n",
    "def flatten_cap_dem_dict(cap_dem_dict, num_airports):\n",
    "    cap_dem_dict_flat = {}\n",
    "    for i in range(num_airports):\n",
    "        cap_dem_dict_flat['req_{}'.format(i)] = cap_dem_dict['req_{}'.format(i)].flatten()\n",
    "    return cap_dem_dict_flat\n",
    "\n",
    "def get_airport_req_dict(requests_full, num_airports):\n",
    "    airport_req_dict = {}\n",
    "    _belong_airport_dict = {}\n",
    "    for i in range(num_airports):\n",
    "        airport_req_dict['req_{}'.format(i)] = np.empty((0, 15)) #This one depends on the number of elements of a final request\n",
    "        _belong_airport_dict['req_{}'.format(i)] = np.full(num_airports, 0.0, dtype=float)\n",
    "        _belong_airport_dict['req_{}'.format(i)][i] = float(1.0)\n",
    "        _belong_airport_dict['req_{}'.format(i)] = _belong_airport_dict['req_{}'.format(i)].tolist()\n",
    "        \n",
    "    for i in range(len(requests_full)):\n",
    "        _found_dep = 0\n",
    "        _found_arv = 0\n",
    "        for k in range(num_airports):\n",
    "            #_found_dep = 0\n",
    "            #_found_arv = 0\n",
    "            if requests_full[i][5] == _belong_airport_dict['req_{}'.format(k)]:\n",
    "                _dep_req = np.append(requests_full[i], 1)\n",
    "                _dep_req = np.append(_dep_req, 0)\n",
    "                airport_req_dict['req_{}'.format(k)] = np.vstack((airport_req_dict['req_{}'.format(k)], _dep_req))\n",
    "                _found_dep = 1\n",
    "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 1)\n",
    "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 0)\n",
    "                #break\n",
    "            if requests_full[i][6] == _belong_airport_dict['req_{}'.format(k)]:\n",
    "                _arv_req = np.append(requests_full[i], 0)\n",
    "                _arv_req = np.append(_arv_req, 1)\n",
    "                airport_req_dict['req_{}'.format(k)] = np.vstack((airport_req_dict['req_{}'.format(k)], _arv_req))\n",
    "                _found_arv = 1\n",
    "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 0)\n",
    "                #airport_req_dict['req_{}'.format(k)] = np.append(airport_req_dict['req_{}'.format(k)], 1)\n",
    "                #break\n",
    "            if _found_dep + _found_arv == 2:\n",
    "                break\n",
    "        if _found_dep + _found_arv != 2:\n",
    "            print(\"Cannot found both dep and arv at req {}\".format(i))\n",
    "            \n",
    "    return airport_req_dict, _belong_airport_dict\n",
    "def generate_deterministic_capacity_dict(num_airports, cap_per_airport_arr): #This function is for a period of 182 days and 288 slots/ day\n",
    "    cap_dict = {}\n",
    "    for i in range(num_airports):\n",
    "        cap_dict['req_{}'.format(i)] = np.full((288, 182), cap_per_airport_arr[i])\n",
    "    return cap_dict\n",
    "\n",
    "def get_initial_pot_dem_per_airport(airport_req_dict, num_airports): #Replace req_df to req_df_update to update pot_dem_df #To be replaced with final_sched\n",
    "    pot_dem_dict = {}\n",
    "    #TODO: increase speed\n",
    "    #13 dep 14 arv, 1 dep ts, 9 arv ts\n",
    "    for i in range(num_airports):\n",
    "        pot_dem_dict['req_{}'.format(i)] = np.full((288, 182), 0)\n",
    "        for k in range(len(airport_req_dict['req_{}'.format(i)])):\n",
    "            _time_slot = int(airport_req_dict['req_{}'.format(i)][k][1]) * int(airport_req_dict['req_{}'.format(i)][k][13]) + int(airport_req_dict['req_{}'.format(i)][k][9]) * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
    "            _date_seq = airport_req_dict['req_{}'.format(i)][k][4] * int(airport_req_dict['req_{}'.format(i)][k][13]) + airport_req_dict['req_{}'.format(i)][k][11] * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
    "            pot_dem_dict['req_{}'.format(i)][_time_slot, _date_seq] += 1\n",
    "    return pot_dem_dict\n",
    "\n",
    "def get_cap_dem_dict(num_airports, cap_dict, pot_dem_dict):\n",
    "    cap_dem_dict = {}\n",
    "    for i in range(num_airports):\n",
    "        cap_dem_dict['req_{}'.format(i)] = cap_dict['req_{}'.format(i)] - pot_dem_dict['req_{}'.format(i)]\n",
    "    return cap_dem_dict\n",
    "\n",
    "def update_status_capacity(airport_req_dict, num_airports, cap_dem_dict, requests_full):\n",
    "    #Them cot cap_status o init:\n",
    "    for i in range(num_airports):\n",
    "        for k in range(len(airport_req_dict['req_{}'.format(i)])):\n",
    "            _time_slot = int(airport_req_dict['req_{}'.format(i)][k][1]) * int(airport_req_dict['req_{}'.format(i)][k][13]) + int(airport_req_dict['req_{}'.format(i)][k][9]) * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
    "            _date_seq = airport_req_dict['req_{}'.format(i)][k][4] * int(airport_req_dict['req_{}'.format(i)][k][13]) + airport_req_dict['req_{}'.format(i)][k][11] * int(airport_req_dict['req_{}'.format(i)][k][14])\n",
    "            if all(x >= 0 for x in cap_dem_dict['req_{}'.format(i)][_time_slot, _date_seq]):\n",
    "                #print(self.cap_dem_arr[_time_slot, _date_seq])\n",
    "                airport_req_dict['req_{}'.format(i)][k][8] = 0\n",
    "                airport_req_dict['req_{}'.format(i)][k][12] = 0\n",
    "            else:\n",
    "                if airport_req_dict['req_{}'.format(i)][k][13] == 1:\n",
    "                    airport_req_dict['req_{}'.format(i)][k][8] = 1\n",
    "                    _indices = np.where(requests_full[:, 0] == airport_req_dict['req_{}'.format(i)][k][0])\n",
    "                    requests_full[_indices, 8] = 1\n",
    "                else:\n",
    "                    airport_req_dict['req_{}'.format(i)][k][12] = 1\n",
    "                    _indices = np.where(requests_full[:, 0] == airport_req_dict['req_{}'.format(i)][k][0])\n",
    "                    requests_full[_indices, 12] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoAirportSchedEnv(gym.Env):\n",
    "    def __init__(self, number_of_actions, number_of_requests, num_airports, cap_per_airport_arr):\n",
    "        \n",
    "        super(TwoAirportSchedEnv, self).__init__()\n",
    "        self.number_of_actions = int(number_of_actions)\n",
    "        self.number_of_requests = number_of_requests\n",
    "        self.num_airports = num_airports\n",
    "        #self.number_of_days = number_of_days\n",
    "        self.cap_per_airport_arr = cap_per_airport_arr\n",
    "        self.cap_dict = generate_deterministic_capacity_dict(self.num_airports, self.cap_per_airport_arr)\n",
    "        #self.generate_scenario()\n",
    "        #update the code to add generate scenario \n",
    "        self.requests_full, self.airport_req_dict, self._belong_airport_dict, self.pot_dem_dict, self.cap_dem_dict = generate_scenario(number_of_requests, num_airports, cap_dict = self.cap_dict)\n",
    "        #to generate action:\n",
    "        self.action_space = spaces.Discrete(self.number_of_actions)\n",
    "        self.observation_space = spaces.Box(low= -np.inf, high= np.inf, shape=(7,), dtype=float)\n",
    "        self.agents = self.initialize_agents()\n",
    "\n",
    "        #cap_dem_dict_flat = flatten_cap_dem_dict(cap_dem_dict, num_airports)\n",
    "        #_generate = True\n",
    "        update_status_capacity(self.airport_req_dict, self.num_airports, self.cap_dem_dict, self.requests_full)\n",
    "        #for i in range(len(self.requests_full)):\n",
    "        #  #print(self.requests_full[i][8], self.requests_full[i][12])\n",
    "        \n",
    "        _exceed_cap = 0         \n",
    "        while _exceed_cap == 0:\n",
    "            self.requests_full, self.airport_req_dict, self._belong_airport_dict, self.pot_dem_dict, self.cap_dem_dict = generate_scenario(number_of_requests = self.number_of_requests, num_airports = self.num_airports, cap_dict = self.cap_dict)\n",
    "            self.cap_dem_dict_flat = flatten_cap_dem_dict(self.cap_dem_dict, self.num_airports)\n",
    "            for i in range(num_airports):\n",
    "                _exceed_cap = _exceed_cap + (min(self.cap_dem_dict_flat['req_{}'.format(i)]))\n",
    "        \n",
    "\n",
    "        update_status_capacity(self.airport_req_dict, self.num_airports, self.cap_dem_dict, self.requests_full)\n",
    "        self.num_step = 0\n",
    "        \n",
    "        #to choose the request that will be checked\n",
    "        self.get_req()\n",
    "\n",
    "        self.dep_time_slot = self.chosen_req[1]\n",
    "        self.original_requests = self.requests_full\n",
    "\n",
    "    def initialize_agents(self):\n",
    "        # Create a dictionary of agents where key is the airport id and value is the agent object\n",
    "        agent_dict = {}\n",
    "        for airport_id in range(self.num_airports):  # assuming you have self.num_airports in TwoAirportSchedEnv\n",
    "            agent = AirportAgent(airport_id, self.num_airports, self.number_of_actions)\n",
    "            agent_dict[airport_id] = agent\n",
    "        return agent_dict\n",
    "    \n",
    "    def get_agent(self, airport_type):\n",
    "        # Check for airport type\n",
    "        if airport_type == \"departure\":\n",
    "            airport_index = self.chosen_req[5].index(1.0)\n",
    "        elif airport_type == \"arrival\":\n",
    "            airport_index = self.chosen_req[6].index(1.0)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid airport_type: {airport_type}. Expected 'departure' or 'arrival'.\")\n",
    "\n",
    "        agent = self.agents.get(airport_index)\n",
    "        return agent\n",
    "    \n",
    "    def action_mapping(self, action, number_of_actions):\n",
    "        mid_point = (number_of_actions - 1) // 2\n",
    "        return action - mid_point\n",
    "    \n",
    "    #added get request to know which is the request we are going to move at this step\",\n",
    "    def get_req(self):\n",
    "        violate_set=get_violate_id_set(self.airport_req_dict, num_airports)\n",
    "        _violate_index = random.choice(violate_set)\n",
    "        self.chosen_req = self.requests_full[self.requests_full[:,0] == _violate_index][0]\n",
    "    \n",
    "    #need to check arrival time or change the variable to check_outbound(arv) and chec_outbound(dep)\n",
    "    def check_outbound(self, action):\n",
    "        dep_time_slot = self.chosen_req[1]\n",
    "        arv_time_slot = self.chosen_req[9]\n",
    "\n",
    "        outbound = False\n",
    "\n",
    "        new_dep_time_slot = dep_time_slot + action\n",
    "        new_arv_time_slot = arv_time_slot + action\n",
    "\n",
    "        if (new_dep_time_slot < 0) or (new_dep_time_slot > 287) or (new_arv_time_slot < 0) or (new_arv_time_slot > 287):\n",
    "            outbound = True\n",
    "\n",
    "        return outbound\n",
    "    \n",
    "    def dep_or_arv(self):\n",
    "        pass\n",
    "\n",
    "    def update_dem(self, dep_airport, arv_airport, time_slot_dep, time_slot_arv, new_time_slot_dep, new_time_slot_arv, date_seq_dep, date_seq_arv):\n",
    "        # Increment demand for the new time slot for both departure and arrival airports\n",
    "        self.pot_dem_dict['req_{}'.format(dep_airport)][new_time_slot_dep, date_seq_dep] += 1\n",
    "        self.pot_dem_dict['req_{}'.format(arv_airport)][new_time_slot_arv, date_seq_arv] += 1\n",
    "\n",
    "        # Decrease demand for the initial time slot for both departure and arrival airports\n",
    "        self.pot_dem_dict['req_{}'.format(dep_airport)][time_slot_dep, date_seq_dep] -= 1\n",
    "        self.pot_dem_dict['req_{}'.format(arv_airport)][time_slot_arv, date_seq_arv] -= 1\n",
    "\n",
    "    def update_cap_dem(self):\n",
    "        for airport in range(self.num_airports):\n",
    "            cap_key = 'req_{}'.format(airport)\n",
    "            dem_key = 'req_{}'.format(airport)\n",
    "            if cap_key not in self.cap_dict:\n",
    "                raise KeyError(f\"'{cap_key}' not found in cap_dict. Available keys: {list(self.cap_dict.keys())}\")\n",
    "            self.cap_dem_dict[cap_key] = self.cap_dict[cap_key] - self.pot_dem_dict[dem_key]\n",
    "\n",
    "    # Need to validate\n",
    "    def update_violate_set(curr_violate, not_violate_update, violate_update):\n",
    "        curr_violate = set(curr_violate)\n",
    "        for req_index in not_violate_update:\n",
    "            curr_violate.remove(req_index)\n",
    "        for req_index in violate_update:\n",
    "            curr_violate.add(req_index) \n",
    "        curr_violate = list(curr_violate)\n",
    "        return curr_violate \n",
    "    \n",
    "    def take_action(self,state,eps):\n",
    "        # Step 1: Randomly choose actions\n",
    "        # action_dep = self.action_space.sample()  # For the departure airport\n",
    "        # action_arv = self.action_space.sample()  # For the arrival airport\n",
    "        self.dep_agent = self.get_agent('departure')\n",
    "        self.arv_agent = self.get_agent('arrival')\n",
    "        print(state)\n",
    "        action_dep = self.dep_agent.act(state,eps)\n",
    "        action_arv = self.arv_agent.act(state,eps)\n",
    "\n",
    "        #Step 2: Check if actions match\n",
    "        # matched_action = None\n",
    "        while action_dep != action_arv:\n",
    "            return 1\n",
    "\n",
    "        return action_dep\n",
    "    \n",
    "    def when_take_action(self, action):\n",
    "        # num_actions = self.number_of_actions\n",
    "        # # Convert the discrete action to your desired action value\n",
    "        # real_action = self.action_mapping(action, num_actions)        \n",
    "\n",
    "        _index = self.chosen_req[0]\n",
    "        time_slot_dep = self.chosen_req[1]\n",
    "        time_slot_arv = self.chosen_req[9]\n",
    "        time_slot_arv = int(time_slot_arv)\n",
    "        _dep_airport = self.chosen_req[5].index(1.0)\n",
    "        _arv_airport = self.chosen_req[6].index(1.0)\n",
    "        _date_seq_dep = self.chosen_req[4]\n",
    "        _date_seq_arv = self.chosen_req[11]\n",
    "        _start_date_dep = self.chosen_req[2]\n",
    "        _start_date_arv = self.chosen_req[10]\n",
    "        _num_weeks = self.chosen_req[3]\n",
    "        # new_time_slot_dep = time_slot_dep + real_action\n",
    "        new_time_slot_dep = time_slot_dep + action\n",
    "        # new_time_slot_arv = time_slot_arv + real_action\n",
    "        new_time_slot_arv = time_slot_arv + action\n",
    "        new_time_slot_arv = int(new_time_slot_arv)\n",
    "        new_date_seq_dep = _date_seq_dep\n",
    "        new_date_seq_arv = _date_seq_arv\n",
    "\n",
    "        outbound = self.check_outbound(action)\n",
    "\n",
    "        if not outbound:\n",
    "            pass\n",
    "            \n",
    "        elif outbound:\n",
    "            # Adjust the departure time slot as needed\n",
    "            if new_time_slot_dep < 0:\n",
    "                new_time_slot_dep = 287  # Move to the last time slot of the previous day\n",
    "                new_start_date_dep = _start_date_dep - 1\n",
    "                new_date_seq_dep = get_date_seq(new_start_date_dep, _num_weeks)\n",
    "            elif new_time_slot_dep > 287:\n",
    "                new_time_slot_dep = 0  # Move to the first time slot of the next day\n",
    "                new_start_date_dep = _start_date_dep + 1\n",
    "                new_date_seq_dep = get_date_seq(new_start_date_dep, _num_weeks)\n",
    "            # Adjust the departure time slot as needed\n",
    "            if new_time_slot_arv < 0:\n",
    "                # Assume that we only move by max one slot for a timeslot change\n",
    "                new_time_slot_arv = 287  # Move to the last time slot of the previous day\n",
    "                new_time_slot_arv = int(new_time_slot_arv)\n",
    "                new_start_date_arv = _start_date_arv - 1\n",
    "                new_date_seq_arv = get_date_seq(new_start_date_arv, _num_weeks)\n",
    "            elif new_time_slot_dep > 287:\n",
    "                # Assume that we only move by max one slot for a timeslot change\n",
    "                new_time_slot_dep = 0  # Move to the first time slot of the next day\n",
    "                new_time_slot_arv = int(new_time_slot_arv)\n",
    "                new_start_date_arv = _start_date_arv + 1\n",
    "                new_date_seq_arv = get_date_seq(new_start_date_arv, _num_weeks)\n",
    "\n",
    "        else:\n",
    "            print('Problem with check outbound!')\n",
    "            \n",
    "        # Update the request for both departure and arrival time slots and dates\n",
    "        self.requests_full[self.requests_full[:, 0] == _index][:, 1] = new_time_slot_dep\n",
    "        self.requests_full[self.requests_full[:, 0] == _index][:, 9] = new_time_slot_arv\n",
    "        # self.requests_full[self.requests_full[:, 0] == _index][:, 4] = new_date_seq_dep\n",
    "        # self.requests_full[self.requests_full[:, 0] == _index][:, 11] = new_date_seq_arv\n",
    "        _index_matching = np.where(self.requests_full[:, 0] == _index)[0][0]\n",
    "        self.requests_full[_index_matching, 4] = new_date_seq_dep\n",
    "        self.requests_full[_index_matching, 11] = new_date_seq_arv\n",
    "\n",
    "        # Update the airport request dict\n",
    "        self.airport_req_dict['req_{}'.format(_dep_airport)][self.airport_req_dict['req_{}'.format(_dep_airport)][:, 0] == _index][:, 1] = new_time_slot_dep\n",
    "        self.airport_req_dict['req_{}'.format(_dep_airport)][self.airport_req_dict['req_{}'.format(_dep_airport)][:, 0] == _index][:, 9] = new_time_slot_arv\n",
    "        self.airport_req_dict['req_{}'.format(_arv_airport)][self.airport_req_dict['req_{}'.format(_arv_airport)][:, 0] == _index][:, 1] = new_time_slot_dep\n",
    "        self.airport_req_dict['req_{}'.format(_arv_airport)][self.airport_req_dict['req_{}'.format(_arv_airport)][:, 0] == _index][:, 9] = new_time_slot_arv\n",
    "\n",
    "        # Update demand for the new time slots\n",
    "        self.update_dem(_dep_airport, _arv_airport, time_slot_dep, time_slot_arv, new_time_slot_dep, new_time_slot_arv, new_date_seq_dep, new_date_seq_arv)\n",
    "        \n",
    "        # Update cap_dem \n",
    "        self.update_cap_dem()\n",
    "\n",
    "        # Update status capacity after the cap_dem table is updated\n",
    "        update_status_capacity(self.airport_req_dict, self.num_airports, self.cap_dem_dict, self.requests_full)\n",
    "\n",
    "    def step(self,state,eps):\n",
    "        action = self.take_action(state,eps)\n",
    "        num_actions = self.number_of_actions\n",
    "        # agent_actions = [agent.action_mapping(action, num_actions) for action, agent in zip(action, self.agents)]\n",
    "        # Convert the discrete action to your desired action value\n",
    "        real_action = self.action_mapping(action, num_actions)       \n",
    "        _num_weeks = self.chosen_req[3]\n",
    "        self.when_take_action(real_action)\n",
    "        outbound = self.check_outbound(real_action)\n",
    "\n",
    "        # Reward part:\n",
    "        local_reward = 0\n",
    "        if outbound:\n",
    "            local_reward = -1\n",
    "        else:\n",
    "            local_reward = 0.1*(-abs(real_action)*0.5*_num_weeks) #TODO change if increase number of actions\n",
    "        \n",
    "        self.num_step += 1\n",
    "        done = False\n",
    "        if self.chosen_req[8] == 0 and self.chosen_req[12] == 0:\n",
    "            done = True\n",
    "            obs = np.zeros((self.number_of_actions + 1,))\n",
    "            global_reward = 100\n",
    "\n",
    "        elif self.num_step == self.number_of_requests*5:\n",
    "            done = True\n",
    "            obs = np.zeros((self.number_of_actions + 1,))\n",
    "            negative_sum = 500\n",
    "            for value in self.cap_dem_dict.values():\n",
    "                # Assuming each value is a numeric value or a numpy array\n",
    "                # If it's a numpy array, you can sum all negative values directly using numpy\n",
    "                if isinstance(value, np.ndarray):\n",
    "                    negative_sum += np.sum(value[value < 0])\n",
    "                else:\n",
    "                    # If it's a single numeric value, just check if it's negative\n",
    "                    if value < 0:\n",
    "                        negative_sum += value\n",
    "            global_reward = negative_sum*10\n",
    "\n",
    "        else:\n",
    "            global_reward = 0\n",
    "            obs = self._next_observation()\n",
    "            # obs = np.zeros((self.number_of_actions + 1,))\n",
    "\n",
    "        reward_time_step = -0.5\n",
    "            \n",
    "        total_reward = float(local_reward + global_reward + reward_time_step)\n",
    "    \n",
    "        \n",
    "\n",
    "        self.dep_agent.step(state,action,total_reward,obs,done)\n",
    "        self.arv_agent.step(state,action,total_reward,obs,done)\n",
    "\n",
    "        #for those airport that are not affected\n",
    "        for id,agent in self.agents.items():\n",
    "            if id != self.dep_agent.airport_id and id != self.arv_agent.airport_id:\n",
    "                agent.step(state,action,reward_time_step,obs,done)\n",
    "        \n",
    "        return obs, total_reward, done, {} \n",
    "    \n",
    "    def _next_observation(self):\n",
    "        self.get_req()\n",
    "        _ts_dep = self.chosen_req[1]\n",
    "        _ts_arv = self.chosen_req[9]\n",
    "        _num_of_weeks = self.chosen_req[3]\n",
    "        _date_seq_dep = self.chosen_req[4]\n",
    "        _date_seq_arv = self.chosen_req[11]\n",
    "        _dep_airport = self.chosen_req[5].index(1.0)\n",
    "        _arv_airport = self.chosen_req[6].index(1.0)\n",
    "        cap_dem_arr_dep = self.cap_dem_dict['req_{}'.format(_dep_airport)]\n",
    "        cap_dem_arr_arv = self.cap_dem_dict['req_{}'.format(_arv_airport)]\n",
    "        _cap_dem_dep = cap_dem_arr_dep[:, _date_seq_dep].copy()\n",
    "        _cap_dem_arv = cap_dem_arr_arv[:, _date_seq_arv].copy()\n",
    "\n",
    "        _obs_min_arr_dep = full_obs(_cap_dem_dep, self.number_of_actions)\n",
    "        _obs_min_arr_arr = full_obs(_cap_dem_arv, self.number_of_actions)\n",
    "        _obs_time_slot_related_dep = list(range(int(_ts_dep), int(_ts_dep + self.number_of_actions), 1))\n",
    "        _obs_time_slot_related_arv = list(range(int(_ts_arv), int(_ts_arv + self.number_of_actions), 1))\n",
    "        _cap_dem_obs_dep = _obs_min_arr_dep[_obs_time_slot_related_dep]\n",
    "        _cap_dem_obs_arv = _obs_min_arr_arr[_obs_time_slot_related_arv]\n",
    "\n",
    "        # Appending _cap_dem_obs_arv to _cap_dem_obs_dep\n",
    "        self.obs = np.append(_cap_dem_obs_dep, _cap_dem_obs_arv)\n",
    "        # append _num_of_weeks to the result of the above, do the following:\n",
    "        self.obs = np.append(self.obs, _num_of_weeks)\n",
    "        \n",
    "        return self.obs\n",
    "\n",
    "    def reset(self):    \n",
    "        # # Reset each agent\n",
    "        # for agent in self.agents.values():\n",
    "        #     agent.reset()    \n",
    "            \n",
    "        generate_scenario(self.number_of_requests, self.num_airports, cap_dict = self.cap_dict)\n",
    "        _dep_airport = self.chosen_req[5].index(1.0)\n",
    "        _arv_airport = self.chosen_req[6].index(1.0)\n",
    "        cap_dem_arr_dep = self.cap_dem_dict['req_{}'.format(_dep_airport)]\n",
    "        cap_dem_arr_arv = self.cap_dem_dict['req_{}'.format(_arv_airport)]\n",
    "        \n",
    "        _cap_dem_flat_dep = cap_dem_arr_dep.flatten()\n",
    "        _cap_dem_flat_arv = cap_dem_arr_arv.flatten()\n",
    "\n",
    "        while (min(_cap_dem_flat_dep) >= 0 or min(_cap_dem_flat_arv) >= 0):\n",
    "            generate_scenario(self.number_of_requests, self.num_airports, cap_dict = self.cap_dict)\n",
    "            _cap_dem_flat_dep = cap_dem_arr_dep.flatten()\n",
    "            _cap_dem_flat_arv = cap_dem_arr_arv.flatten()\n",
    "        \n",
    "        update_status_capacity(self.airport_req_dict, self.num_airports, self.cap_dem_dict, self.requests_full)\n",
    "        print('Number of violation for dep: ', len(_cap_dem_flat_dep[_cap_dem_flat_dep < 0]))\n",
    "        print('Number of violation for arv: ', len(_cap_dem_flat_arv[_cap_dem_flat_arv < 0]))\n",
    "\n",
    "        self.num_step = 0        \n",
    "        return self._next_observation()\n",
    "    \n",
    "    # Need to validate\n",
    "    def eval(self):\n",
    "        _dep_airport = self.chosen_req[5].index(1.0)\n",
    "        _arv_airport = self.chosen_req[6].index(1.0)\n",
    "        _initial_cap_dem_dict = {}\n",
    "        _initial_pot_dem_dict = get_initial_pot_dem_per_airport(self.airport_req_dict, self.num_airports)\n",
    "        for airport in range(self.num_airports):\n",
    "            cap_key = 'req_{}'.format(airport)\n",
    "            dem_key = 'req_{}'.format(airport)\n",
    "            _initial_cap_dem_dict[cap_key] = self.cap_dict[cap_key] - _initial_pot_dem_dict[dem_key]\n",
    "\n",
    "        _initial_cap_dem_dep = self.cap_dem_dict['req_{}'.format(_dep_airport)]\n",
    "        _initial_cap_dem_flat_dep = _initial_cap_dem_dep.flatten()\n",
    "        _initial_violate_dep = len(_initial_cap_dem_flat_dep[_initial_cap_dem_flat_dep < 0])\n",
    "        print('Initial violation of departure is: ', _initial_violate_dep)\n",
    "        _initial_cap_dem_arv = self.cap_dem_dict['req_{}'.format(_arv_airport)]\n",
    "        _initial_cap_dem_flat_arv = _initial_cap_dem_arv.flatten()\n",
    "        _initial_violate_arv = len(_initial_cap_dem_flat_arv[_initial_cap_dem_flat_arv < 0])\n",
    "        print('Initial violation of arrival is: ', _initial_violate_arv)\n",
    "\n",
    "        cap_dem_arr_dep = self.cap_dem_dict['req_{}'.format(_dep_airport)]\n",
    "        cap_dem_arr_arv = self.cap_dem_dict['req_{}'.format(_arv_airport)]\n",
    "        _final_cap_dem_flat_dep = cap_dem_arr_dep.flatten()\n",
    "        _final_cap_dem_flat_arv = cap_dem_arr_arv.flatten()\n",
    "        _final_violate_dep = len(_final_cap_dem_flat_dep[_final_cap_dem_flat_dep < 0])\n",
    "        _final_violate_arv = len(_final_cap_dem_flat_arv[_final_cap_dem_flat_arv < 0])\n",
    "        print('Final violation of departure is: ', _final_violate_dep)\n",
    "        print('Final violation of arrival is: ', _final_violate_arv)\n",
    "\n",
    "        _total_sched_delay_dep = sum(abs(self.original_requests[:,1] - self.requests_full[:,1])* self.original_requests[:,3])\n",
    "        print('Total schedule delay of departure is: ', _total_sched_delay_dep)\n",
    "        _total_sched_delay_arv = sum(abs(self.original_requests[:,9] - self.requests_full[:,9])* self.original_requests[:,3])\n",
    "        print('Total schedule delay of arrival is: ', _total_sched_delay_arv)\n",
    "\n",
    "        _max_shift_dep = max(abs(self.original_requests[:,1] - self.requests_full[:,1]))\n",
    "        print('Max shift of departure: ', _max_shift_dep)\n",
    "        _max_shift_arv = max(abs(self.original_requests[:,9] - self.requests_full[:,9]))\n",
    "        print('Max shift of arrival: ', _max_shift_arv)\n",
    "\n",
    "        _unaccom_req_dep = len(self.requests_full[self.requests_full[:,8] == 1])\n",
    "        print('Number of unaccommodate departure requests: ', _unaccom_req_dep)\n",
    "        _unaccom_req_arv = len(self.requests_full[self.requests_full[:,12] == 1])\n",
    "        print('Number of unaccommodate arrival requests: ', _unaccom_req_arv)\n",
    "\n",
    "        return _initial_violate_dep, _initial_violate_arv, _final_violate_dep, _final_violate_arv, _total_sched_delay_dep, _total_sched_delay_arv, _max_shift_dep, _max_shift_arv, _unaccom_req_dep, _unaccom_req_arv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \"\"\" Actor (Policy) Model.\"\"\"\n",
    "    def __init__(self, state_size,action_size, seed, fc1_unit=64,\n",
    "                 fc2_unit = 64):\n",
    "        \"\"\"\n",
    "        Initialize parameters and build model.\n",
    "        Params\n",
    "        =======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_unit (int): Number of nodes in first hidden layer\n",
    "            fc2_unit (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork,self).__init__() ## calls __init__ method of nn.Module class\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1= nn.Linear(state_size,fc1_unit)\n",
    "        # print(seed)\n",
    "        self.fc2 = nn.Linear(fc1_unit,fc2_unit)\n",
    "        self.fc3 = nn.Linear(fc2_unit,action_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x = state\n",
    "        \"\"\"\n",
    "        Build a network that maps state -> action values.\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  #replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate\n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class AirportAgent():\n",
    "    \"\"\"Interacts with and learns form environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, airport_id, num_airports, number_of_actions):\n",
    "    # self, state_size, action_size, seed\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        =======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        super(AirportAgent, self).__init__()\n",
    "\n",
    "        self.airport_id = airport_id\n",
    "        self.num_airports = num_airports\n",
    "        self.number_of_actions = number_of_actions\n",
    "        self.action_space = spaces.Discrete(self.number_of_actions)\n",
    "        self.rewards = []\n",
    "        self.state = one_hot_encode_airport(self.airport_id, self.num_airports)\n",
    "        self.state_size = 7\n",
    "        self.action_size = 3\n",
    "        self.seed = random.seed(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Q- Network\n",
    "        self.qnetwork_local = QNetwork(self.state_size, self.action_size, seed=0).to(device)\n",
    "        self.qnetwork_target = QNetwork(self.state_size, self.action_size,seed=0).to(device)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(),lr=LR)\n",
    "        \n",
    "        # Replay memory \n",
    "        self.memory = ReplayBuffer(self.action_size, BUFFER_SIZE,BATCH_SIZE,seed=0)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "\n",
    "    def set(self):\n",
    "        return self.state\n",
    "    \n",
    "    def action_mapping(self, action, number_of_actions):\n",
    "        mid_point = (number_of_actions - 1) // 2\n",
    "        return action - mid_point\n",
    "        \n",
    "    def step(self, state, action, reward, next_step, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_step, done)\n",
    "\n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step+1)% UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get radom subset and learn\n",
    "\n",
    "            if len(self.memory)>BATCH_SIZE:\n",
    "                experience = self.memory.sample()\n",
    "                self.learn(experience, GAMMA)\n",
    "    def act(self, state, eps = 0):\n",
    "        \"\"\"Returns action for given state as per current policy\n",
    "        Params\n",
    "        =======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        #Epsilon -greedy action selction\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "            \n",
    "    # def learn(self, experiences, gamma):\n",
    "    #     \"\"\"Update value parameters using given batch of experience tuples.\n",
    "    #     Params\n",
    "    #     =======\n",
    "    #         experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples\n",
    "    #         gamma (float): discount factor\n",
    "    #     \"\"\"\n",
    "    #     states, actions, rewards, next_states, dones = experiences\n",
    "    #     ## TODO: compute and minimize the loss\n",
    "    #     criterion = torch.nn.MSELoss()\n",
    "    #     # Local model is one which we need to train so it's in training mode\n",
    "    #     self.qnetwork_local.train()\n",
    "    #     # Target model is one with which we need to get our target so it's in evaluation mode\n",
    "    #     # So that when we do a forward pass with target model it does not calculate gradient.\n",
    "    #     # We will update target model weights with soft_update function\n",
    "    #     self.qnetwork_target.eval()\n",
    "    #     #shape of output from the model (batch_size,action_dim) = (64,4)\n",
    "    #     predicted_targets = self.qnetwork_local(states).gather(1,actions)\n",
    "    \n",
    "    #     with torch.no_grad():\n",
    "    #         labels_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "\n",
    "    #     # .detach() ->  Returns a new Tensor, detached from the current graph.\n",
    "    #     labels = rewards + (gamma* labels_next*(1-dones))\n",
    "        \n",
    "    #     loss = criterion(predicted_targets,labels).to(device)\n",
    "    #     self.optimizer.zero_grad()\n",
    "    #     loss.backward()\n",
    "    #     self.optimizer.step()\n",
    "\n",
    "    #     # ------------------- update target network ------------------- #\n",
    "    #     self.soft_update(self.qnetwork_local,self.qnetwork_target,TAU)\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "        Params\n",
    "        =======\n",
    "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples\n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        ## TODO: compute and minimize the loss\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        self.qnetwork_local.train()\n",
    "        self.qnetwork_target.eval()\n",
    "        #shape of output from the model (batch_size,action_dim) = (64,4)\n",
    "        predicted_targets = self.qnetwork_local(states).gather(1,actions)\n",
    "\n",
    "        #################Updates for Double DQN learning###########################\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            actions_q_local = self.qnetwork_local(next_states).detach().max(1)[1].unsqueeze(1).long()\n",
    "            labels_next = self.qnetwork_target(next_states).gather(1,actions_q_local)\n",
    "        self.qnetwork_local.train()\n",
    "        ############################################################################\n",
    "\n",
    "        # .detach() ->  Returns a new Tensor, detached from the current graph.\n",
    "        labels = rewards + (gamma* labels_next*(1-dones))\n",
    "\n",
    "        loss = criterion(predicted_targets,labels).to(device)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local,self.qnetwork_target,TAU)\n",
    "            \n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        Params\n",
    "        =======\n",
    "            local model (PyTorch model): weights will be copied from\n",
    "            target model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter\n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(),\n",
    "                                           local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1-tau)*target_param.data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed -size buffe to store experience tuples.\"\"\"\n",
    "    \n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        \n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experiences = namedtuple(\"Experience\", field_names=[\"state\",\n",
    "                                                               \"action\",\n",
    "                                                               \"reward\",\n",
    "                                                               \"next_state\",\n",
    "                                                               \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "    def add(self,state, action, reward, next_state,done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experiences(state,action,reward,next_state,done)\n",
    "        self.memory.append(e)\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory\"\"\"\n",
    "        experiences = random.sample(self.memory,k=self.batch_size)\n",
    "        \n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        \n",
    "        return (states,actions,rewards,next_states,dones)\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of violation for dep:  1465\n",
      "Number of violation for arv:  1508\n",
      "[ 0 -2 -2  6  4  4  8]\n",
      "Episode 1\tAverage Score -0.90[ 6 -1  1  5 -1  1  6]\n",
      "Episode 1\tAverage Score -1.15[ 6  7  6 -3 -1 -3  8]\n",
      "Episode 1\tAverage Score -1.53[-3 -2 -2 -1  0 -2  7]\n",
      "Episode 1\tAverage Score -1.85[ 4 -1  5  0 -8 -5  7]\n",
      "Episode 1\tAverage Score -2.14[ 1 -3 -5 -1 -2  4  9]\n",
      "Episode 1\tAverage Score -2.49[-3 -1  0  3  2  0 19]\n",
      "Episode 1\tAverage Score -2.95[ 5  0  4 -3 -4  1 17]\n",
      "Episode 1\tAverage Score -3.46[ 3 -2  0  2  0  0  8]\n",
      "Episode 1\tAverage Score -3.92[ 1 -5  0  4  7  8  5]\n",
      "Episode 1\tAverage Score -4.35Number of violation for dep:  1509\n",
      "Number of violation for arv:  1605\n",
      "[ 0 -1  1 -2 -3 -3 11]\n",
      "Episode 2\tAverage Score -4.00[ 2 -8 -3  2 -3 -2  6]\n",
      "Episode 2\tAverage Score -3.75[-5 -4  1  1 -2  6 14]\n",
      "Episode 2\tAverage Score -3.58[-2  0  5  0 -4  0  7]\n",
      "Episode 2\tAverage Score -3.47[ 9  6  9  3 -3 -4  7]\n",
      "Episode 2\tAverage Score -3.40[-4  0 -1  5 -5  1 15]\n",
      "Episode 2\tAverage Score -3.38[ 6  4  2  2 -1 -3  9]\n",
      "Episode 2\tAverage Score -3.39[ 9  3  8  1 -6  2  6]\n",
      "Episode 2\tAverage Score -3.42[-6 -2  1  2  2  4 10]\n",
      "Episode 2\tAverage Score -3.48[ 2 -5  2  5  3  4 16]\n",
      "Episode 2\tAverage Score -3.59Number of violation for dep:  1601\n",
      "Number of violation for arv:  1458\n",
      "[ 5 -1  3  4  1  2  5]\n",
      "Episode 3\tAverage Score -3.45[-6 -1  1  3  4  4 16]\n",
      "Episode 3\tAverage Score -3.37[-5  1 -1  3 -1  1  7]\n",
      "Episode 3\tAverage Score -3.32[-3 -3 -3 -4  0  1 13]\n",
      "Episode 3\tAverage Score -3.30[ 0 -1  3  6  5  4 13]\n",
      "Episode 3\tAverage Score -3.30[ 3 -1  3 -4 -1  1 22]\n",
      "Episode 3\tAverage Score -3.36[ 0 -4  2  0 -3  0 11]\n",
      "Episode 3\tAverage Score -3.46[ 3  6  3 -1 -4  4  6]\n",
      "Episode 3\tAverage Score -3.58[-4 -4  1  6  2  9 10]\n",
      "Episode 3\tAverage Score -3.72[ 6  4  1 -4 -6 -2 17]\n",
      "Episode 3\tAverage Score -3.87Number of violation for dep:  1598\n",
      "Number of violation for arv:  1455\n",
      "[ 0 -2 -2  8  4  2  6]\n",
      "Episode 4\tAverage Score -3.76[ 7  0 -1 -4 -5 -6  8]\n",
      "Episode 4\tAverage Score -3.68[ 0 -8 -5  3  2  4 23]\n",
      "Episode 4\tAverage Score -3.61[ 7 -4  4  8  6  9  6]\n",
      "Episode 4\tAverage Score -3.56[ 5 -1  2  2 -4  1  9]\n",
      "Episode 4\tAverage Score -3.53[ 3 -1  1  4  2  3  9]\n",
      "Episode 4\tAverage Score -3.52[-8 -1 -3  3  2  5 19]\n",
      "Episode 4\tAverage Score -3.52[-1 -7  0  0  2  0  6]\n",
      "Episode 4\tAverage Score -3.53[ 3 -7  2  4  4  8  5]\n",
      "Episode 4\tAverage Score -3.56[ 4 -5 -1  8  5  6 11]\n",
      "Episode 4\tAverage Score -3.60Number of violation for dep:  1509\n",
      "Number of violation for arv:  1456\n",
      "[ 4  2  0 -2 -5 -8  5]\n",
      "Episode 5\tAverage Score -3.53[  1  -4 -10   4   2  -4  19]\n",
      "Episode 5\tAverage Score -3.47[ 1 -1 -3  4  2  2  5]\n",
      "Episode 5\tAverage Score -3.42[-3 -2 -1 -3 -1  3  7]\n",
      "Episode 5\tAverage Score -3.39[-2 -1 -1  3  4  2 10]\n",
      "Episode 5\tAverage Score -3.37[-4  4 -3 -2 -4  2 15]\n",
      "Episode 5\tAverage Score -3.36[ 0 -1 -1  3  0  0 14]\n",
      "Episode 5\tAverage Score -3.37[ 1 -1 -4 -1  3  3  9]\n",
      "Episode 5\tAverage Score -3.38[-4 -3 -1  4  0  2 21]\n",
      "Episode 5\tAverage Score -3.40[-4 -3 -1  4  0  2 21]\n",
      "Episode 5\tAverage Score -3.43Number of violation for dep:  1509\n",
      "Number of violation for arv:  1598\n",
      "[ 4 -4 -4  4  2 -2 12]\n",
      "Episode 6\tAverage Score -3.38[ 0 -1  2  2  2  0  7]\n",
      "Episode 6\tAverage Score -3.33[-1 -5  4  7  2 -3  6]\n",
      "Episode 6\tAverage Score -3.30[-1  0 -2  2 -1 -4  8]\n",
      "Episode 6\tAverage Score -3.27[-5 -3 -7  1 -1  1  7]\n",
      "Episode 6\tAverage Score -3.26[-3 -6  3  4  1  6  5]\n",
      "Episode 6\tAverage Score -3.25[ 5 -3  0  6  0  5 12]\n",
      "Episode 6\tAverage Score -3.27[-1 -1  3 -2  1  3 14]\n",
      "Episode 6\tAverage Score -3.29[-4 -3 -2  0 -4  4  9]\n",
      "Episode 6\tAverage Score -3.32[-2 -8 -1  4  3  2  6]\n",
      "Episode 6\tAverage Score -3.36Number of violation for dep:  1512\n",
      "Number of violation for arv:  1598\n",
      "[ 0 -2 -4  2 -4  1 19]\n",
      "Episode 7\tAverage Score -3.31[ 0 -1 -1  3  0  0 14]\n",
      "Episode 7\tAverage Score -3.28[ 0 -4 -2  4 -2  4  5]\n",
      "Episode 7\tAverage Score -3.25[ 2 -2  1  2  3  3 11]\n",
      "Episode 7\tAverage Score -3.23[-1 -3  3  3 -2  6  6]\n",
      "Episode 7\tAverage Score -3.22[ 6  3  6 -3 -3  1  6]\n",
      "Episode 7\tAverage Score -3.21[ 7 -1 -5  0  0 -1 12]\n",
      "Episode 7\tAverage Score -3.22[ 1  1  3 -3 -3  0 19]\n",
      "Episode 7\tAverage Score -3.23[ 8  6  4  2 -3 -1 13]\n",
      "Episode 7\tAverage Score -3.25[-2 -5 -2 -2 -2  4 16]\n",
      "Episode 7\tAverage Score -3.27Number of violation for dep:  1598\n",
      "Number of violation for arv:  1456\n",
      "[ 1  3  0  2 -6  0  9]\n",
      "Episode 8\tAverage Score -3.23[-3 -1  0  4  3  3  7]\n",
      "Episode 8\tAverage Score -3.20[ 7  6  8  2 -4 -3  7]\n",
      "Episode 8\tAverage Score -3.18[ 3 -2  4  0 -3 -2  5]\n",
      "Episode 8\tAverage Score -3.16[ 1 -3 -6  4  5  2  5]\n",
      "Episode 8\tAverage Score -3.15[ 1 -1 -4  0  2 -5  5]\n",
      "Episode 8\tAverage Score -3.16[-3 -7 -3  2  4  5 11]\n",
      "Episode 8\tAverage Score -3.17[ 1 -1 -5 -1  1  1  5]\n",
      "Episode 8\tAverage Score -3.19[-2  2  4  2 -4  2 11]\n",
      "Episode 8\tAverage Score -3.23[ 9  7  3  0 -2  2  5]\n",
      "Episode 8\tAverage Score -3.27Number of violation for dep:  1596\n",
      "Number of violation for arv:  1456\n",
      "[ 6 -1  1  9  8  9 10]\n",
      "Episode 9\tAverage Score -3.24[ 1  0 -3  4 -2 -2  7]\n",
      "Episode 9\tAverage Score -3.22[ 2 -3 -6  2 -2  3 11]\n",
      "Episode 9\tAverage Score -3.20[ 1 -3 -6  7  5  4  6]\n",
      "Episode 9\tAverage Score -3.20[-3 -9  1  1  2  6  5]\n",
      "Episode 9\tAverage Score -3.19[-1 -4 -4  1  0  0 15]\n",
      "Episode 9\tAverage Score -3.20[ 4  4  1  3 -1  2 21]\n",
      "Episode 9\tAverage Score -3.22[ 1 -2  0  5  0  3  8]\n",
      "Episode 9\tAverage Score -3.25[-3 -6 -4 -1  1  2 21]\n",
      "Episode 9\tAverage Score -3.30[ 8  3  5 -3 -9 -1 12]\n",
      "Episode 9\tAverage Score -3.35Number of violation for dep:  1597\n",
      "Number of violation for arv:  1512\n",
      "[ 0 -3  4  6 -2  2 12]\n",
      "Episode 10\tAverage Score -3.32[ 2 -3 -1  3 -4  0  5]\n",
      "Episode 10\tAverage Score -3.29[ 2 -3 -4  3  5  4 12]\n",
      "Episode 10\tAverage Score -3.27[-5 -6  2  7  7  9 10]\n",
      "Episode 10\tAverage Score -3.26[ 7  7  7  5 -3  5 11]\n",
      "Episode 10\tAverage Score -3.26[-4  2 -3 -6 -3 -3 10]\n",
      "Episode 10\tAverage Score -3.27[ 5  0  1  1 -2  0  7]\n",
      "Episode 10\tAverage Score -3.28[ 2 -6  2  9  8  8  5]\n",
      "Episode 10\tAverage Score -3.30[-3 -6  4  6  2  6  6]\n",
      "Episode 10\tAverage Score -3.32[ 3  1  3 -1 -1  3 13]\n",
      "Episode 10\tAverage Score -3.35"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# env = gym.make('LunarLander-v2')\n",
    "env = TwoAirportSchedEnv(number_of_actions=3, number_of_requests=15000, num_airports=3, cap_per_airport_arr= [9,9,9])\n",
    "\n",
    "def dqn(n_episodes= 1000, max_t = 5000, eps_start=1.0, eps_end = 0.01,\n",
    "       eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training epsiodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon \n",
    "        eps_decay (float): mutiplicative factor (per episode) for decreasing epsilon\n",
    "        \n",
    "    \"\"\"\n",
    "    scores = [] # list containing score from each episode\n",
    "    scores_window = deque(maxlen=100) # last 100 scores\n",
    "    eps = eps_start\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        # print(state)\n",
    "        # print(type(state))\n",
    "        # print(np.asarray(state[0]))\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            # print(np.asarray(state[0]))\n",
    "            # print(\"here\")\n",
    "            # action = agent.act(state,eps) # put this into env.take_action\n",
    "            \n",
    "            # print(action)\n",
    "            # print(env.step(action))obs, total_reward, done, {}\n",
    "            next_state,reward,done,_ = env.step(state,eps)\n",
    "            # print(next_state)\n",
    "            # agent.step(state,action,reward,next_state,done) #move this into env\n",
    "            ## above step decides whether we will train(learn) the network\n",
    "            ## actor (local_qnetwork) or we will fill the replay buffer\n",
    "            ## if len replay buffer is equal to the batch size then we will\n",
    "            ## train the network or otherwise we will add experience tuple in our \n",
    "            ## replay buffer.\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break\n",
    "            scores_window.append(score) ## save the most recent score\n",
    "            scores.append(score) ## sae the most recent score\n",
    "            eps = max(eps*eps_decay,eps_end)## decrease the epsilon\n",
    "            print('\\rEpisode {}\\tAverage Score {:.2f}'.format(i_episode,np.mean(scores_window)), end=\"\")\n",
    "            if i_episode %100==0:\n",
    "                print('\\rEpisode {}\\tAverage Score {:.2f}'.format(i_episode,np.mean(scores_window)))\n",
    "                \n",
    "            if np.mean(scores_window)>=100.0:\n",
    "                print('\\nEnvironment solve in {:d} epsiodes!\\tAverage score: {:.2f}'.format(i_episode-100,\n",
    "                                                                                           np.mean(scores_window)))\n",
    "                torch.save(agent.qnetwork_local.state_dict(),'checkpoint.pth')\n",
    "                break\n",
    "    return scores\n",
    "\n",
    "scores= dqn()\n",
    "\n",
    "#plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)),scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Epsiode #')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoint.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/reginachua/Documents/RL/DQN.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/reginachua/Documents/RL/DQN.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#load the weights from file\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/reginachua/Documents/RL/DQN.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m agent \u001b[39m=\u001b[39m Agent(state_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,action_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,seed\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/reginachua/Documents/RL/DQN.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m agent\u001b[39m.\u001b[39mqnetwork_local\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mcheckpoint.pth\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/reginachua/Documents/RL/DQN.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/reginachua/Documents/RL/DQN.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoint.pth'"
     ]
    }
   ],
   "source": [
    "#load the weights from file to test model\n",
    "# agent = Agent(state_size=8,action_size=4,seed=0)\n",
    "# agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "# for i in range(3):\n",
    "#     state = env.reset()\n",
    "#     img = plt.imshow(env.render(mode='rgb_array'))\n",
    "#     for j in range(200):\n",
    "#         action = agent.act(state)\n",
    "#         img.set_data(env.render(mode='rbg_array'))\n",
    "#         plt.axix('off')\n",
    "#         display.display(plt.gcf())\n",
    "#         display.clear_output(wait=True)\n",
    "#         state,reward,done,_ = env.step(action)\n",
    "#         if done:\n",
    "#             break\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
